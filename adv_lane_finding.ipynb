{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "2. Apply a distortion correction to raw images.\n",
    "3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "5. Detect lane pixels and fit to find the lane boundary.\n",
    "6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "7. Warp the detected lane boundaries back onto the original image.\n",
    "8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "source": [
    "## 1. Implementation\n",
    "\n",
    "This project was developed to dynamicaly calibrate each step and feature implemented on it through opencv trackbars. This way it is easier to understand and interact with each method implemented and directly see what happens in the output of each step.\n",
    "\n",
    "Run the following cells and follow the instructions specified to interact with this simulation.\n",
    "\n",
    "Complete explanation (writeup) is on the README.md "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 1.1. Libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs used in this project\n",
    "import numpy as np\n",
    "import time\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt"
   ]
  },
  {
   "source": [
    "## 1.2. Global Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize global parameters with previous calibrated values\n",
    "\n",
    "# Define globaly original image size\n",
    "img_size = [1280,720]\n",
    "\n",
    "# Color and Gradient Threshold\n",
    "hls_threshold = (160,255)\n",
    "sobel_threshold = (19,105)\n",
    "\n",
    "# Warp perspective auxiliar variables to compute source and destination vertices to be used by cal_perspective_matrix()\n",
    "dst_horizontal_offset = 360\n",
    "src_roi_upper = 450\n",
    "src_horizontal_offset_upper = 47\n",
    "src_horizontal_offset_lower = 457\n",
    "src_horizontal_drift_upper_l = 0\n",
    "src_horizontal_drift_upper_r = 0\n",
    "src_horizontal_drift_lower_l = 0\n",
    "src_horizontal_drift_lower_r = 0\n",
    "\n",
    "# Sliding Window hyperparams:\n",
    "nwindows = 9\n",
    "margin = 100\n",
    "minpix = 50\n",
    "\n",
    "# Search Around hyperparams:\n",
    "margin_sa = 100\n",
    "\n",
    "# moving Average max length:\n",
    "moving_avg_max_count = 12\n",
    "\n",
    "# Initialize Lanes polynomial fit average arrays with empty values\n",
    "left_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "right_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "lane_lines_dist_base = 690\n",
    "ym_per_px = 30/720 # meters per pixel in y dimension\n",
    "xm_per_px = 3.7/690 # meters per pixel in x dimension\n"
   ]
  },
  {
   "source": [
    "## 1.3. Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and return the camera calibration matrix and distortion coefficients using a set of chessboard images\n",
    "def cal_camera_calibration(calibration_imgs_glob_path='camera_cal/calibration*.jpg', num_vertices_x=9, num_vertices_y=6,show=False):\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((num_vertices_y*num_vertices_x,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:num_vertices_x,0:num_vertices_y].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(calibration_imgs_glob_path)\n",
    "\n",
    "    print(\"Start camera calibration...\")\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img_camera_calibration = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img_camera_calibration,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (num_vertices_x,num_vertices_y),None)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            if show:\n",
    "                img_camera_calibration = cv2.drawChessboardCorners(img_camera_calibration, (num_vertices_x,num_vertices_y), corners, ret)\n",
    "                cv2.imshow('Camera calibration',img_camera_calibration)\n",
    "                cv2.waitKey(100)\n",
    "\n",
    "    if show:\n",
    "        cv2.destroyWindow(\"Camera calibration\")\n",
    "\n",
    "    # Get calibration image shape\n",
    "    cal_img = cv2.imread(images[0])\n",
    "    cal_img_shape = cal_img.shape[1::-1]\n",
    "\n",
    "    # Calculate camera calibration params\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, cal_img_shape, None, None)\n",
    "\n",
    "    print(\"Camera calibrated! RMS re-projection error (retval): {}\".format(ret))\n",
    "\n",
    "    return ret, mtx, dist\n",
    "\n",
    "\n",
    "# Returns undistorted image using the camera intrinsic and extrinsic parameters previously calculated\n",
    "def cal_undistort(img, mtx, dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist\n",
    "\n",
    "\n",
    "# Return the combined binary image of Sobel and S Channel thresholded\n",
    "def cal_threshold(img,hls_threshold=(170, 255),sobel_threshold=(20, 100),color_space=\"RGB\"):\n",
    "\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    if color_space == \"RGB\":\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    else:\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sobel_threshold[0]) & (scaled_sobel <= sobel_threshold[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= hls_threshold[0]) & (s_channel <= hls_threshold[1])] = 1\n",
    "\n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "\n",
    "    return combined_binary,sxbinary,s_binary,h_channel,l_channel,s_channel\n",
    "\n",
    "\n",
    "# Calculate and return the perspective transform matrix and source/destination vertices arrays\n",
    "def cal_perspective_matrix(img_size_x,img_size_y):\n",
    "    # Define warp source vertices \n",
    "    src_vertices = np.array(\n",
    "    [[img_size_x/2 - src_horizontal_offset_lower + src_horizontal_drift_lower_l , img_size_y],\n",
    "        [img_size_x/2 - src_horizontal_offset_upper + src_horizontal_drift_upper_l , src_roi_upper], \n",
    "        [img_size_x/2 + src_horizontal_offset_upper + src_horizontal_drift_upper_r , src_roi_upper], \n",
    "        [img_size_x/2 + src_horizontal_offset_lower + src_horizontal_drift_lower_r , img_size_y]],\n",
    "        np.float32)\n",
    "\n",
    "    # Define warp destination vertices \n",
    "    dst_vertices = np.array(\n",
    "    [[img_size_x/2 - dst_horizontal_offset, img_size_y],\n",
    "        [img_size_x/2 - dst_horizontal_offset, 0],\n",
    "        [img_size_x/2 + dst_horizontal_offset, 0], \n",
    "        [img_size_x/2 + dst_horizontal_offset, img_size_y]],\n",
    "        np.float32)\n",
    "\n",
    "    # Calculate the warp transformation matrix M\n",
    "    M = cv2.getPerspectiveTransform(src_vertices, dst_vertices)\n",
    "    \n",
    "    return src_vertices, dst_vertices, M\n",
    "\n",
    "# Return the perspective transform of the given image\n",
    "def cal_perspective(img_to_warp, M, inverted=False):\n",
    "    \n",
    "    # get input image proper width-height size accordingly to it's shape\n",
    "    img_to_warp_size = None\n",
    "    if len(img_to_warp.shape) > 2:\n",
    "        img_to_warp_size = img_to_warp.shape[1::-1]\n",
    "    else:\n",
    "        img_to_warp_size = img_to_warp.shape[::-1]\n",
    "        img_to_warp = img_to_warp*255\n",
    "    \n",
    "    if inverted:\n",
    "        # Warp the image using the inverted perspective transform matrix flag\n",
    "        warped = cv2.warpPerspective(img_to_warp, M, img_to_warp_size,flags=cv2.WARP_INVERSE_MAP | cv2.INTER_LINEAR)\n",
    "    else:\n",
    "        # Warp the image using perspective transform matrix\n",
    "        warped = cv2.warpPerspective(img_to_warp, M, img_to_warp_size)\n",
    "\n",
    "    return warped\n",
    "\n",
    "\n",
    "def cal_sliding_window(img_warped,nwindows=9,margin=100,minpix=50,draw=True):\n",
    "\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(img_warped[img_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    img_binary_out = np.dstack((img_warped, img_warped, img_warped))\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(img_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        if draw:\n",
    "            cv2.rectangle(img_binary_out,(win_xleft_low,win_y_low),\n",
    "            (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "            cv2.rectangle(img_binary_out,(win_xright_low,win_y_low),\n",
    "            (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    left_fit, right_fit, left_fitx, right_fitx, fity = cal_fit_polynomial(img_warped.shape[0],leftx,lefty,rightx,righty,clear_ma=True)\n",
    "\n",
    "    if draw:\n",
    "        # Color in left and right line pixels\n",
    "        img_binary_out[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        img_binary_out[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Draw the left and right polynomials on top of the img_binary_out image\n",
    "        if len(left_fitx) > 0 and len(right_fitx) > 0 :\n",
    "            lane_l = np.dstack((left_fitx, fity))[0]\n",
    "            lane_r = np.dstack((right_fitx, fity))[0]\n",
    "            cv2.polylines(img_binary_out,np.int32([lane_l]),False,(0,255,255),thickness=3)\n",
    "            cv2.polylines(img_binary_out,np.int32([lane_r]),False,(0,255,255),thickness=3)\n",
    "\n",
    "    return left_fit, right_fit, left_fitx, right_fitx, fity, img_binary_out\n",
    "\n",
    "\n",
    "def cal_search_around_poly(img_warped, margin_sa=100, draw=True):\n",
    "\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    img_binary_out = np.dstack((img_warped, img_warped, img_warped))*255\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = img_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Calculate the currente lane lines fit averages\n",
    "    left_fit_avg_arr_filtered = [ arr for arr in left_fit_avg_arr if len(arr)>0 ]\n",
    "    right_fit_avg_arr_filtered = [ arr for arr in right_fit_avg_arr if len(arr)>0 ]\n",
    "\n",
    "    left_fit_avg = np.array([])\n",
    "    right_fit_avg = np.array([])\n",
    "\n",
    "    if len(left_fit_avg_arr_filtered)>0 and len(right_fit_avg_arr_filtered)>0:\n",
    "        left_fit_avg = np.mean(left_fit_avg_arr_filtered,axis=0)\n",
    "        right_fit_avg = np.mean(right_fit_avg_arr_filtered,axis=0)\n",
    "    \n",
    "    # If any average arrays is empty, then return with empty values. This might be an error durting calibration\n",
    "    else:\n",
    "        return left_fit_avg, right_fit_avg, np.array([]), np.array([]), np.array([]), img_binary_out\n",
    "\n",
    "    # Set the area of search based on activated x-values\n",
    "    left_lane_inds = ((nonzerox > (left_fit_avg[0]*(nonzeroy**2) + left_fit_avg[1]*nonzeroy + \n",
    "                    left_fit_avg[2] - margin_sa)) & (nonzerox < (left_fit_avg[0]*(nonzeroy**2) + \n",
    "                    left_fit_avg[1]*nonzeroy + left_fit_avg[2] + margin_sa)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit_avg[0]*(nonzeroy**2) + right_fit_avg[1]*nonzeroy + \n",
    "                    right_fit_avg[2] - margin_sa)) & (nonzerox < (right_fit_avg[0]*(nonzeroy**2) + \n",
    "                    right_fit_avg[1]*nonzeroy + right_fit_avg[2] + margin_sa)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Calculate the new fit polynomial\n",
    "    left_fit, right_fit, left_fitx, right_fitx, fity = cal_fit_polynomial(img_warped.shape[0],leftx,lefty,rightx,righty)\n",
    "\n",
    "    if draw:\n",
    "        window_img = np.zeros_like(img_binary_out)\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin_sa, fity]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin_sa, \n",
    "                                fity])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin_sa, fity]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin_sa, \n",
    "                                fity])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        img_binary_out = cv2.addWeighted(img_binary_out, 1, window_img, 0.3, 0)\n",
    "\n",
    "        # Color in left and right line pixels\n",
    "        img_binary_out[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        img_binary_out[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Draw the left and right polynomials on top of the img_binary_out image\n",
    "        if len(left_fitx) > 0 and len(right_fitx) > 0 :\n",
    "            lane_l = np.dstack((left_fitx, fity))[0]\n",
    "            lane_r = np.dstack((right_fitx, fity))[0]\n",
    "            cv2.polylines(img_binary_out,np.int32([lane_l]),False,(0,255,255),thickness=3)\n",
    "            cv2.polylines(img_binary_out,np.int32([lane_r]),False,(0,255,255),thickness=3)\n",
    "    \n",
    "    \n",
    "    return left_fit, right_fit, left_fitx, right_fitx, fity, img_binary_out\n",
    "\n",
    "\n",
    "def cal_fit_polynomial(img_size_y, leftx, lefty, rightx, righty, clear_ma=False):\n",
    "    global left_fit_avg_arr\n",
    "    global right_fit_avg_arr\n",
    "\n",
    "    # Reset lanes polynomial fit average arrays if requested\n",
    "    if clear_ma:\n",
    "        left_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "        right_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "\n",
    "    # Calculate new fit polynomial values\n",
    "    try:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    except TypeError:\n",
    "        left_fit = []\n",
    "    \n",
    "    try:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    except TypeError:\n",
    "        right_fit = []\n",
    "\n",
    "    # Append the new value to the moving average array\n",
    "    left_fit_avg_arr.append(left_fit) \n",
    "    right_fit_avg_arr.append(right_fit) \n",
    "\n",
    "    # Remove first (older) value and trim array to max moving average elements\n",
    "    left_fit_avg_arr = left_fit_avg_arr[1:moving_avg_max_count+1]\n",
    "    right_fit_avg_arr = right_fit_avg_arr[1:moving_avg_max_count+1]\n",
    "    \n",
    "    # Filter only not empty arrays\n",
    "    left_fit_avg_arr_filtered = [ arr for arr in left_fit_avg_arr if len(arr)>0 ]\n",
    "    right_fit_avg_arr_filtered = [ arr for arr in right_fit_avg_arr if len(arr)>0 ]\n",
    "\n",
    "    # Build 2 element arrays to store left and right lane line variables together\n",
    "    lanes_fit = [left_fit_avg_arr_filtered,right_fit_avg_arr_filtered]\n",
    "    lanes_fit_avg = [np.array([]),np.array([])]\n",
    "    lanes_fitx = [np.array([]),np.array([])]\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    fity = np.linspace(0, img_size_y-1, img_size_y)\n",
    "\n",
    "    # Calculate average fit and x values for each lane side\n",
    "    for i in range(len(lanes_fit)):\n",
    "        if len(lanes_fit[i]) > 0:\n",
    "            try:\n",
    "                lanes_fit_avg[i] = np.mean(lanes_fit[i],axis=0)\n",
    "                lanes_fitx[i] = lanes_fit_avg[i][0]*fity**2 + lanes_fit_avg[i][1]*fity + lanes_fit_avg[i][2]\n",
    "            except TypeError:\n",
    "                print('cal_fit_polynomial(): Failed to fit {} line!'.format('left' if i == 0 else 'right'))\n",
    "                lanes_fitx[i] = np.array([])\n",
    "\n",
    "    return lanes_fit_avg[0], lanes_fit_avg[1], lanes_fitx[0], lanes_fitx[1], fity\n",
    "\n",
    "\n",
    "# Draw the lane lines area on the undistorted image\n",
    "def draw_lane_area(img_undistorted, M, img_warped, left_fit, right_fit, left_fitx, right_fitx, fity):\n",
    "    if len(img_warped.shape) <= 2:\n",
    "        img_warped_filtered = np.dstack((img_warped, img_warped, img_warped))\n",
    "    else:\n",
    "        img_warped_filtered = np.copy(img_warped)\n",
    "\n",
    "    white_threshold = (img_warped_filtered[:,:,0] > 0 ) & (img_warped_filtered[:,:,1] > 0 ) & (img_warped_filtered[:,:,2] > 0 )\n",
    "    green_threshold = (img_warped_filtered[:,:,0] == 0 ) & (img_warped_filtered[:,:,1] > 0 ) & (img_warped_filtered[:,:,2] == 0 )\n",
    "\n",
    "    # Clear green (margin area to perform sliding window or search around) and white pixels (not considered in calculations)\n",
    "    img_warped_filtered[white_threshold | green_threshold] = [0,0,0]\n",
    "\n",
    "    window_img = np.zeros_like(img_warped_filtered)\n",
    "    lane_window1 = np.array([np.transpose(np.vstack([left_fitx, fity]))])\n",
    "    lane_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx, fity])))])\n",
    "\n",
    "    lane_pts = np.hstack((lane_window1,lane_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([lane_pts]), (0,255, 0))\n",
    "\n",
    "    # Merge Lane area with lane lines \n",
    "    img_warped_filtered = cv2.addWeighted(img_warped_filtered, 1, window_img, 0.3, 0)\n",
    "    \n",
    "    # Inverse warp the image using inverted perspective transform matrix\n",
    "    warped_inv = cal_perspective(img_warped_filtered, M, inverted=True)\n",
    "\n",
    "    # Find colored pixels locations\n",
    "    colored_threshold = (warped_inv[:,:,0] > 0 ) | (warped_inv[:,:,1] > 0 ) | (warped_inv[:,:,2] > 0 )\n",
    "\n",
    "    # Create a pre mask with lane area drawn on it to get stronger colors\n",
    "    img_lanes_aux = cv2.addWeighted(img_undistorted, 0.6, warped_inv, 1.0, 0)\n",
    "    \n",
    "    # Substitute the pre mask lane area pixels in the original undistorted image, to preserve pixel values from other areas\n",
    "    img_lanes = np.copy(img_undistorted)\n",
    "    img_lanes[colored_threshold] = img_lanes_aux[colored_threshold] \n",
    "\n",
    "    return img_lanes\n",
    "\n",
    "# Calculate lane lines curvature based on the calculated polynomial fit and xy conversion factor to meters\n",
    "def cal_lane_curvature(fity, left_fit_cr, right_fit_cr, factor_x=xm_per_px, factor_y=ym_per_px):\n",
    "    \n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(fity)\n",
    "\n",
    "    # Calculate new polynomial fit with converted values by factors\n",
    "    # left_fit = np.array([left_fit[0]*factor_x/(factor_y**2), left_fit[1]*factor_x/factor_y, left_fit[2]*factor_x])\n",
    "    # right_fit = np.array([right_fit[0]*factor_x/(factor_y**2), right_fit[1]*factor_x/factor_y, right_fit[2]*factor_x])\n",
    "    \n",
    "    # Build an array of x values with given polynomial fit coefficients\n",
    "    left_fitx = left_fit_cr[0]*fity**2 + left_fit_cr[1]*fity + left_fit_cr[2]\n",
    "    right_fitx = right_fit_cr[0]*fity**2 + right_fit_cr[1]*fity + right_fit_cr[2]\n",
    "\n",
    "    # Multply x and y arrays for the respective factors, and then calculate the new polynomial fit coefficients\n",
    "    left_fit_cr_m = np.polyfit(fity*factor_y, left_fitx*factor_x, 2)\n",
    "    right_fit_cr_m = np.polyfit(fity*factor_y, right_fitx*factor_x, 2)\n",
    "\n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_fit_cr_m[0]*y_eval*factor_y + left_fit_cr_m[1])**2)**1.5) / np.absolute(2*left_fit_cr_m[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr_m[0]*y_eval*factor_y + right_fit_cr_m[1])**2)**1.5) / np.absolute(2*right_fit_cr_m[0])\n",
    "    \n",
    "    return left_curverad, right_curverad\n",
    "\n",
    "# Reset lanes polynomial fit average arrays\n",
    "def reset_ma():\n",
    "    global left_fit_avg_arr\n",
    "    global right_fit_avg_arr\n",
    "    left_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "    right_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "\n",
    "# Return both lane lines sides array without empty values\n",
    "def get_fit_avg_arr_filtered():\n",
    "    left_fit_avg_arr_filtered = [ arr for arr in left_fit_avg_arr if len(arr)>0 ]\n",
    "    right_fit_avg_arr_filtered = [ arr for arr in right_fit_avg_arr if len(arr)>0 ]\n",
    "\n",
    "    return left_fit_avg_arr_filtered, right_fit_avg_arr_filtered\n",
    "\n",
    "# Compose an image array in a single image\n",
    "def compose_image_arr(img_list,max_columns,title_list=[],resize_factor = 0.4):\n",
    "    \n",
    "    # Check if is enough images to complete the last img composition line and add blank image if needed\n",
    "    if len(img_list) % max_columns > 0:\n",
    "        blk = np.copy(img)*0\n",
    "        for i in range(max_columns - (len(img_list) % max_columns)):\n",
    "            img_list.append(blk)\n",
    "            title_list.append(\"\")\n",
    "\n",
    "    img_list_2d=[]\n",
    "\n",
    "    for i in range(0,len(img_list)):\n",
    "        # Check if its not a colored image and stack it like a 3 channel color image\n",
    "        if len(img_list[i].shape) == 2:\n",
    "            img_list[i] = np.dstack((img_list[i], img_list[i], img_list[i]))\n",
    "            \n",
    "            # if its a binary, then scale to 255\n",
    "            if np.max(img_list[i]) == 1:\n",
    "                img_list[i] = img_list[i]*255\n",
    "        \n",
    "        # Add image name on the top left corner\n",
    "        if len(title_list)>0:\n",
    "            cv2.putText(img_list[i],title_list[i],(10,40),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,0,255),3,cv2.LINE_AA)\n",
    "\n",
    "        # if it is the first image of a line, add an empty list to be populated next with following images\n",
    "        if (i % max_columns) == 0:\n",
    "            img_list_2d.append([])\n",
    "        img_list_2d[int(i/max_columns)].append(img_list[i])\n",
    "\n",
    "    # Concatenate images making a composition of fixed number of images in width\n",
    "    composed_img = cv2.vconcat([cv2.hconcat(im_list_h) for im_list_h in img_list_2d])\n",
    "    \n",
    "    # Resize whole composition\n",
    "    composed_img_resized = cv2.resize(composed_img, (int(composed_img.shape[1]*resize_factor),int(composed_img.shape[0]*resize_factor)), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return composed_img_resized"
   ]
  },
  {
   "source": [
    "## 1.4. Advance Lane Finding implementation\n",
    "This is the full project implementation that find lane lines on videos with Trackbars on the visualization window for dynamic parameters calibration\n",
    "\n",
    "On the visualization window, press the following letters to trigger commands as described below\n",
    "\n",
    "- `q` exits simulation.\n",
    "- `w` switch to the previous image/video.\n",
    "- `e` switch to the next image/video.\n",
    "- `r` reset move average array.\n",
    "- `a` toggle between image/video input\n",
    "- `s` saves a snapshot to folder `output_images`.\n",
    "- `f` toggle between show only the result and an array of image of each step.\n",
    "- `v` restart current video and start saving the output result to a video file on `/output_videos` folder. Only works on video mode (`a`)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "List of videos: ['challenge_video.mp4', 'harder_challenge_video.mp4', 'project_video.mp4']\n",
      "Start camera calibration...\n",
      "Camera calibrated! RMS re-projection error (retval): 1.0298153371058965\n",
      "Start VideoWriter!\n",
      "Released VideoWriter!\n",
      "\n",
      "\n",
      "Global variables calibration Results:\n",
      "\n",
      "# Color and Gradient Threshold:\n",
      "  hls_threshold: (160,255)\n",
      "  sobel_threshold: (19,105)\n",
      "\n",
      "# Warp perspective:\n",
      "  dst_horizontal_offset = 360\n",
      "\n",
      "# Sliding Window hyperparams:\n",
      "  nwindows = 9\n",
      "  margin = 100\n",
      "  minpix = 50\n",
      "\n",
      "# Search Around hyperparams:\n",
      "  margin_sa = 100\n",
      "\n",
      "# moving Average max length:\n",
      "  moving_avg_max_count = 12\n"
     ]
    }
   ],
   "source": [
    "# Make a list of test images\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "test_images_index = 0\n",
    "\n",
    "# Make a list of test videos\n",
    "test_videos = sorted(glob.glob('*.mp4'))\n",
    "test_videos_index = len(test_videos)-1\n",
    "print(\"List of videos: {}\".format(test_videos))\n",
    "\n",
    "# Initialize cap with first video\n",
    "cap = cv2.VideoCapture(test_videos[test_videos_index])\n",
    "\n",
    "# Create an video frame index\n",
    "cap_counter = 0\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "video_out = None\n",
    "img_name = None\n",
    "\n",
    "# One time execution functions\n",
    "ret, mtx, dist = cal_camera_calibration()\n",
    "src_vertices, dst_vertices, M = cal_perspective_matrix(img_size[0],img_size[1])\n",
    "\n",
    "# image visualization flag\n",
    "only_result_img_show = True\n",
    "input_video_img_flag = True\n",
    "\n",
    "# Create a window with trackbars and callback functions bolow to handle when values are changed\n",
    "cv2_window_name = \"Advanced Lane Finding\"\n",
    "cv2.namedWindow(cv2_window_name)\n",
    "\n",
    "# Threshold trackbars\n",
    "def on_hls_th_l(val):\n",
    "    global hls_threshold\n",
    "    hls_threshold = (val,hls_threshold[1])\n",
    "\n",
    "def on_hls_th_u(val):\n",
    "    global hls_threshold\n",
    "    hls_threshold = (hls_threshold[0],val)\n",
    "\n",
    "def on_sobel_th_l(val):\n",
    "    global sobel_threshold\n",
    "    sobel_threshold = (val,sobel_threshold[1])\n",
    "\n",
    "def on_sobel_th_u(val):\n",
    "    global sobel_threshold\n",
    "    sobel_threshold = (sobel_threshold[0],val)\n",
    "\n",
    "cv2.createTrackbar(\"S Channel Threshold Lower\",cv2_window_name,hls_threshold[0],255,on_hls_th_l)\n",
    "cv2.createTrackbar(\"S Channel Threshold Upper\",cv2_window_name,hls_threshold[1],255,on_hls_th_u)\n",
    "cv2.createTrackbar(\"Sobel Threshold Lower\",cv2_window_name,sobel_threshold[0],255,on_sobel_th_l)\n",
    "cv2.createTrackbar(\"Sobel Threshold Upper\",cv2_window_name,sobel_threshold[1],255,on_sobel_th_u)\n",
    "\n",
    "# Warp perspective Trackbar\n",
    "def on_warp_dst_x_offset(val):\n",
    "    global dst_vertices\n",
    "    global src_vertices\n",
    "    global M\n",
    "    global dst_horizontal_offset\n",
    "    dst_horizontal_offset = val\n",
    "\n",
    "    # Update perspective transform variables\n",
    "    src_vertices, dst_vertices, M = cal_perspective_matrix(img_size[0],img_size[1])\n",
    "    \n",
    "cv2.createTrackbar(\"Dst Horizontal Offset\",cv2_window_name,dst_horizontal_offset,600,on_warp_dst_x_offset)\n",
    "\n",
    "# Polinomial Fit Trackbars\n",
    "def on_nwindows(val):\n",
    "    global nwindows\n",
    "    nwindows = val\n",
    "\n",
    "def on_margin(val):\n",
    "    global margin\n",
    "    margin = val\n",
    "\n",
    "def on_minpix(val):\n",
    "    global minpix\n",
    "    minpix = val\n",
    "\n",
    "def on_margin_sa(val):\n",
    "    global margin_sa\n",
    "    margin_sa = val\n",
    "\n",
    "def on_moving_avg_max_count(val):\n",
    "    global moving_avg_max_count\n",
    "    global leftt_fit_avg_arr\n",
    "    global right_fit_avg_arr\n",
    "\n",
    "    moving_avg_max_count = val\n",
    "\n",
    "    # Check if both lanes polynomial Fit average arrays have length lower than the new one specified, then add empty arrays to fill it to desired length. If it is longer, cal_fit_polynomial() will automatically trim to new length when calculates the new average\n",
    "    if len(left_fit_avg_arr) < moving_avg_max_count:\n",
    "        for i in range(moving_avg_max_count - len(left_fit_avg_arr)):\n",
    "            left_fit_avg_arr.append([])\n",
    "    if len(right_fit_avg_arr) < moving_avg_max_count:\n",
    "        for i in range(moving_avg_max_count - len(right_fit_avg_arr)):\n",
    "            right_fit_avg_arr.append([])\n",
    "\n",
    "cv2.createTrackbar(\"nwindows\",cv2_window_name,nwindows,50,on_nwindows)\n",
    "cv2.createTrackbar(\"margin\",cv2_window_name,margin,200,on_margin)\n",
    "cv2.createTrackbar(\"minpix\",cv2_window_name,minpix,200,on_minpix)\n",
    "cv2.createTrackbar(\"margin_sa\",cv2_window_name,margin_sa,640,on_margin_sa)\n",
    "cv2.createTrackbar(\"moving_avg_len\",cv2_window_name,moving_avg_max_count,60,on_moving_avg_max_count)\n",
    "\n",
    "\n",
    "# Main simulation loop\n",
    "while True:\n",
    "\n",
    "    # Read a frame from video of current index\n",
    "    if input_video_img_flag:\n",
    "        ret,img = cap.read()\n",
    "        cap_counter += 1\n",
    "    else:\n",
    "        # Read image of current index\n",
    "        img = cv2.imread(test_images[test_images_index])\n",
    "\n",
    "    if ret == False and input_video_img_flag:\n",
    "        # Release video writer\n",
    "        if video_out != None:\n",
    "            video_out.release()\n",
    "            print(\"Released VideoWriter!\")\n",
    "            video_out = None\n",
    "        \n",
    "        # Restart VideoCapture with same video\n",
    "        cap = cv2.VideoCapture(test_videos[test_videos_index])\n",
    "        cap_counter = 0\n",
    "        continue\n",
    "\n",
    "    # Undistort image\n",
    "    img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "    # Apply color and gradient threshold to undistorted image\n",
    "    img_und_thresholded = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"BGR\")[0]\n",
    "\n",
    "    # Apply perspective transform to the undistorted thresholded image\n",
    "    img_warped = cal_perspective(img_und_thresholded, M)\n",
    "\n",
    "    left_fit_avg_arr_filtered, right_fit_avg_arr_filtered = get_fit_avg_arr_filtered()\n",
    "\n",
    "    # If both moving average arrays aren't empty\n",
    "    if len(left_fit_avg_arr_filtered) > 0 and len(right_fit_avg_arr_filtered) > 0 :\n",
    "        # Calculate the Search Around method to find lane lines \n",
    "        left_fit, right_fit, left_fitx, right_fitx, fity, img_warped_poly_fit = cal_search_around_poly(img_warped, margin_sa=margin_sa)\n",
    "    else:\n",
    "        # Calculate the Sliding window method to find lane lines \n",
    "        left_fit, right_fit, left_fitx, right_fitx, fity, img_warped_poly_fit = cal_sliding_window(img_warped,nwindows=nwindows,margin=margin,minpix=minpix)\n",
    "\n",
    "    # Check if new polynomial fits average are empty/valid\n",
    "    if len(left_fit) > 0 and len(right_fit) > 0 :\n",
    "        \n",
    "        # Use the nearst pixel of each line from car to calculate lane_lines_dist\n",
    "        lane_lines_dist = right_fitx[-1] - left_fitx[-1]\n",
    "        \n",
    "        # Check if the distance between lanes not is valid (+-20% of lane_lines_dist_base)\n",
    "        if lane_lines_dist < lane_lines_dist_base*0.8 or lane_lines_dist > lane_lines_dist_base*1.2:\n",
    "            print(\"Invalid Lane lines found, reseting moving average\")\n",
    "            # Reset moving average to force finding new lane lines by Sliding window method\n",
    "            reset_ma()\n",
    "\n",
    "        # Draw lane area into the original undistorted image\n",
    "        img_lanes = draw_lane_area(img_undistorted, M, img_warped_poly_fit, left_fit, right_fit, left_fitx, right_fitx, fity)\n",
    "    \n",
    "        # Calculate lane lines curvature\n",
    "        left_curverad, right_curverad = cal_lane_curvature(fity,left_fit,right_fit,factor_x=xm_per_px, factor_y=ym_per_px)\n",
    "\n",
    "        # Calculate the distance from car center to lane center and build a readable string with orientation Left/Right/Center(+-0.1m)\n",
    "        lane_center_diff_x = (float(right_fitx[-1] + left_fitx[-1])/2 - float(img_warped_poly_fit.shape[1])/2)*xm_per_px\n",
    "        lane_center_diff_x_str = \"{:0.2f}m {}\".format(np.absolute(lane_center_diff_x),\"Left\" if lane_center_diff_x > 0.1 else (\"Right\" if lane_center_diff_x < 0.1 else \"Center\"))\n",
    "\n",
    "    else:\n",
    "        lane_center_diff_x_str = \"-\"\n",
    "        left_curverad = 0\n",
    "        right_curverad = 0\n",
    "        img_lanes = img_undistorted\n",
    "\n",
    "    # Write calculated lane information to result image\n",
    "    cv2.putText(img_lanes,\"Distance from lane center: {}\".format(lane_center_diff_x_str),(10,120),cv2.FONT_HERSHEY_SIMPLEX,1.0,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(img_lanes,\"Left Radius: {:0.2f}m | Right Radius: {:0.2f}m\".format(left_curverad, right_curverad),(10,160),cv2.FONT_HERSHEY_SIMPLEX,1.0,(0,0,255),2,cv2.LINE_AA)\n",
    "\n",
    "    # Get current image/video name\n",
    "    if input_video_img_flag:\n",
    "        img_name = test_videos[test_videos_index].split('.')[0]\n",
    "    else:\n",
    "        img_name = test_images[test_images_index].split('/')[1].split('.')[0]\n",
    "\n",
    "    # Check if its to show all steps or only the result. Build the images titles accordingly\n",
    "    if only_result_img_show:\n",
    "\n",
    "        # Stack all images on a single array\n",
    "        img_list=[]\n",
    "        img_list.append(img)\n",
    "        img_list.append(img_undistorted)\n",
    "        img_list.append(img_und_thresholded)\n",
    "        img_list.append(img_warped)\n",
    "        img_list.append(img_warped_poly_fit)\n",
    "        img_list.append(img_lanes)\n",
    "\n",
    "        title_list = [\"[{}]Original\".format(img_name,cap_counter),\"Undistorted\",\"Combined Threshold\",\"Warped\",\"Polynomial Fit\",\"Lane Lines\"]\n",
    "        img_compostion = compose_image_arr(img_list,3,title_list=title_list,resize_factor=0.40)\n",
    "    else:\n",
    "        title_list = [\"[{}]Lane Lines\".format(img_name,cap_counter)]\n",
    "        img_compostion= compose_image_arr([img_lanes],1,title_list=title_list,resize_factor=0.80)\n",
    "\n",
    "    if video_out != None:\n",
    "        video_out.write(img_compostion)\n",
    "\n",
    "    cv2.imshow(cv2_window_name,img_compostion)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # Quit the simulation\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "    # Reset moving average \n",
    "    elif key == ord('r'):\n",
    "        reset_ma()\n",
    "    \n",
    "    # Open the next video\n",
    "    elif key == ord('e'):\n",
    "        if input_video_img_flag:\n",
    "            test_videos_index += 1\n",
    "            if(test_videos_index >= len(test_videos)):\n",
    "                test_videos_index = 0\n",
    "            cap = cv2.VideoCapture(test_videos[test_videos_index])\n",
    "            cap_counter = 0\n",
    "        else:\n",
    "            test_images_index += 1\n",
    "            if(test_images_index >= len(test_images)):\n",
    "                test_images_index = 0\n",
    "        reset_ma()\n",
    "    \n",
    "    # Open the previous video\n",
    "    elif key == ord('w'):\n",
    "        if input_video_img_flag:\n",
    "            test_videos_index -= 1\n",
    "            if(test_videos_index < 0):\n",
    "                test_videos_index = len(test_videos)-1\n",
    "            cap = cv2.VideoCapture(test_videos[test_videos_index])\n",
    "            cap_counter = 0\n",
    "        else:\n",
    "            test_images_index -= 1\n",
    "            if(test_images_index < 0):\n",
    "                test_images_index = len(test_images)-1\n",
    "        reset_ma()\n",
    "    \n",
    "    # Enable/Disable only show the final result image\n",
    "    elif key == ord('f'):\n",
    "        only_result_img_show = False if only_result_img_show else True\n",
    "    \n",
    "    elif key == ord('a'):\n",
    "        input_video_img_flag = False if input_video_img_flag else True\n",
    "\n",
    "        if input_video_img_flag:\n",
    "            cap = cv2.VideoCapture(test_videos[test_videos_index])\n",
    "            cap_counter = 0\n",
    "        elif video_out != None:\n",
    "            # Release video writer\n",
    "            video_out.release()\n",
    "            print(\"Released VideoWriter!\")\n",
    "            video_out = None\n",
    "        reset_ma()\n",
    "\n",
    "    # Save an screenshot\n",
    "    elif key == ord('s'):\n",
    "        ts = int(time.time())\n",
    "        if input_video_img_flag:\n",
    "            img_name = test_videos[test_videos_index].split('.')[0]\n",
    "        else:\n",
    "            img_name = test_images[test_images_index].split('/')[1].split('.')[0]\n",
    "        for i in range(1,len(img_list)):\n",
    "            cv2.imwrite(\"output_images/ts{}_{}_{}.png\".format(ts,img_name,title_list[i]),img_list[i])\n",
    "        cv2.imwrite(\"output_images/ts{}_{}_composition.png\".format(ts,img_name),img_compostion)\n",
    "\n",
    "\n",
    "    # Configure video_out, restart current video and start saving output to video\n",
    "    elif key == ord('v'):\n",
    "        if video_out == None:\n",
    "            ts = int(time.time())\n",
    "            reset_ma()\n",
    "            if input_video_img_flag:\n",
    "                img_name = test_videos[test_videos_index].split('.')[0]\n",
    "                cap = cv2.VideoCapture(test_videos[test_videos_index])\n",
    "                cap_counter = 0\n",
    "            else:\n",
    "                img_name = test_images[test_images_index].split('/')[1].split('.')[0]\n",
    "            print(\"Start VideoWriter!\")\n",
    "            video_out = cv2.VideoWriter(\"ts{}_{}_output.avi\".format(ts,img_name), fourcc, 25.0, (img_compostion.shape[1], img_compostion.shape[0]))\n",
    "        else:\n",
    "            video_out.release()\n",
    "            print(\"Released VideoWriter!\")\n",
    "            video_out = None\n",
    "\n",
    "cap.release()\n",
    "if video_out != None:\n",
    "    video_out.release()\n",
    "    print(\"Released VideoWriter!\")\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print all global variables to manualy update them\n",
    "print(\"\\n\\nGlobal variables calibration Results:\")\n",
    "\n",
    "print(\"\\n# Color and Gradient Threshold:\")\n",
    "print(\"  hls_threshold: ({},{})\".format(hls_threshold[0],hls_threshold[1]))\n",
    "print(\"  sobel_threshold: ({},{})\".format(sobel_threshold[0],sobel_threshold[1]))\n",
    "\n",
    "print(\"\\n# Warp perspective:\")\n",
    "print(\"  dst_horizontal_offset = {}\".format(dst_horizontal_offset))\n",
    "\n",
    "print(\"\\n# Sliding Window hyperparams:\")\n",
    "print(\"  nwindows = {}\".format(nwindows))\n",
    "print(\"  margin = {}\".format(margin))\n",
    "print(\"  minpix = {}\".format(minpix))\n",
    "\n",
    "print(\"\\n# Search Around hyperparams:\")\n",
    "print(\"  margin_sa = {}\".format(margin_sa))\n",
    "\n",
    "print(\"\\n# moving Average max length:\")\n",
    "print(\"  moving_avg_max_count = {}\".format(moving_avg_max_count))"
   ]
  },
  {
   "source": [
    "# 2. Individual Calibrations"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.1. Camera calibration with visualization (require `cv2.imshow`)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start camera calibration...\n",
      "Camera calibrated! RMS re-projection error (retval): 1.0298153371058965\n",
      "\n",
      "ret: 1.0298153371058965\n",
      "mtx:\n",
      "[[1.15777930e+03 0.00000000e+00 6.67111054e+02]\n",
      " [0.00000000e+00 1.15282291e+03 3.86128938e+02]\n",
      " [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\n",
      "dist:\n",
      "[[-0.24688775 -0.02373132 -0.00109842  0.00035108 -0.00258571]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate camera calibration (Set show=False if cv2.imshow is not available)\n",
    "ret, mtx, dist = cal_camera_calibration(show=True)\n",
    "\n",
    "# Read an chessboard image\n",
    "# img = mpimg.imread(\"camera_cal/calibration1.jpg\")\n",
    "img = mpimg.imread(\"test_images/straight_lines1.jpg\")\n",
    "\n",
    "# Undistort image\n",
    "undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "# Plot original image and the undistorted image\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0.0, right=1.0, top=0.9, bottom=0.0)\n",
    "\n",
    "# Save output\n",
    "# plt.savefig(\"output_images/2_1_camera_calibration_undistorted.png\")\n",
    "plt.savefig(\"output_images/2_1_test_image_undistorted.png\")\n",
    "\n",
    "print(\"\\nret: {}\".format(ret))\n",
    "print(\"mtx:\\n\"+str(mtx))\n",
    "print(\"dist:\\n\"+str(dist))"
   ]
  },
  {
   "source": [
    "## 2.2. Color and Gradient threshold dynamic calibration"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calibrated threshold params:\n  hls_threshold: (160,255)\n  sobel_threshold: (19,105)\n"
     ]
    }
   ],
   "source": [
    "# Make a list of test images\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "test_images_index = 0\n",
    "\n",
    "# Create a window with trackbars and callback functions bolow to handle when values are changed\n",
    "cv2.namedWindow(\"Threshold Calibration\")\n",
    "\n",
    "def on_hls_th_l(val):\n",
    "    global hls_threshold\n",
    "    hls_threshold = (val,hls_threshold[1])\n",
    "\n",
    "def on_hls_th_u(val):\n",
    "    global hls_threshold\n",
    "    hls_threshold = (hls_threshold[0],val)\n",
    "\n",
    "def on_sobel_th_l(val):\n",
    "    global sobel_threshold\n",
    "    sobel_threshold = (val,sobel_threshold[1])\n",
    "\n",
    "def on_sobel_th_u(val):\n",
    "    global sobel_threshold\n",
    "    sobel_threshold = (sobel_threshold[0],val)\n",
    "\n",
    "cv2.createTrackbar(\"Color Threshold Lower\",\"Threshold Calibration\",hls_threshold[0],255,on_hls_th_l)\n",
    "cv2.createTrackbar(\"Color Threshold Upper\",\"Threshold Calibration\",hls_threshold[1],255,on_hls_th_u)\n",
    "cv2.createTrackbar(\"Sobel Threshold Lower\",\"Threshold Calibration\",sobel_threshold[0],255,on_sobel_th_l)\n",
    "cv2.createTrackbar(\"Sobel Threshold Upper\",\"Threshold Calibration\",sobel_threshold[1],255,on_sobel_th_u)\n",
    "\n",
    "# Calculate camera calibration\n",
    "ret, mtx, dist = cal_camera_calibration()\n",
    "\n",
    "while True:\n",
    "    img_list=[]\n",
    "\n",
    "    # Read image of current index\n",
    "    img = cv2.imread(test_images[test_images_index])\n",
    "\n",
    "    # Undistort image\n",
    "    img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "    img_und_thresholded,sxbinary,s_binary,h_channel,l_channel,s_channel = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"BGR\")\n",
    "\n",
    "    img_list.append(img)\n",
    "    img_list.append(img_undistorted)\n",
    "    img_list.append(np.zeros_like(img))\n",
    "    img_list.append(h_channel)\n",
    "    img_list.append(l_channel)\n",
    "    img_list.append(s_channel)\n",
    "    img_list.append(sxbinary)\n",
    "    img_list.append(s_binary)\n",
    "    img_list.append(img_und_thresholded)\n",
    "\n",
    "    title_list = [\"[{}]Original\".format(test_images[test_images_index].split('/')[1]),\"Undistorted\",\"\",\"H Channel\",\"L Channel\",\"S Channel\",\"Sobel Threshold\",\"S Channel Threshold\",\"Combined Threshold\"]\n",
    "    img_compostion = compose_image_arr(img_list,3,title_list=title_list,resize_factor=0.40)\n",
    "\n",
    "    cv2.imshow(\"Threshold Calibration\",img_compostion)\n",
    "    key = cv2.waitKey(200) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('w'):\n",
    "        test_images_index += 1\n",
    "        if(test_images_index >= len(test_images)):\n",
    "            test_images_index = 0\n",
    "    elif key == ord('e'):\n",
    "        test_images_index -= 1\n",
    "        if(test_images_index < 0):\n",
    "            test_images_index = len(test_images)-1\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"output_images/2_2_thresholds_calibration.png\",img_compostion)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Calibrated threshold params:\")\n",
    "print(\"  hls_threshold: ({},{})\".format(hls_threshold[0],hls_threshold[1]))\n",
    "print(\"  sobel_threshold: ({},{})\".format(sobel_threshold[0],sobel_threshold[1]))"
   ]
  },
  {
   "source": [
    "## 2.3. Comparisson between original and undistorted image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate camera calibration\n",
    "ret, mtx, dist = cal_camera_calibration()\n",
    "\n",
    "# Read an chessboard image\n",
    "img = mpimg.imread(\"test_images/test1.jpg\")\n",
    "\n",
    "# Undistort image\n",
    "img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "# Apply color and gradient threshold\n",
    "img_thresholded = cal_threshold(img)[0]\n",
    "img_und_thresholded = cal_threshold(img_undistorted)[0]\n",
    "\n",
    "# Plot original image, the undistorted image and the respectives thresholded images\n",
    "f, ((ax1, ax2), (ax3,ax4),(ax5,ax6)) = plt.subplots(3,2, figsize=(12, 11))\n",
    "# f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=15)\n",
    "ax2.imshow(img_undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=15)\n",
    "ax3.imshow(img_thresholded, cmap='gray')\n",
    "ax3.set_title('Thresholded Image', fontsize=15)\n",
    "ax4.imshow(img_und_thresholded, cmap='gray')\n",
    "ax4.set_title('Thresholded Undistorted Image', fontsize=15)\n",
    "\n",
    "# Check differences between the original and undistorted binary thresholds\n",
    "diff_binary = np.zeros_like(img_thresholded)\n",
    "diff_binary[((img_thresholded == 0) & (img_und_thresholded == 1)) | ((img_thresholded == 1) & (img_und_thresholded == 0))] = 1\n",
    "# diff_binary[(img_thresholded == 0) & (img_und_thresholded == 1)] = 1\n",
    "color_diff_binary = np.dstack(( img_thresholded,img_und_thresholded,np.zeros_like(img_und_thresholded))) * 255\n",
    "\n",
    "ax5.imshow(diff_binary, cmap='gray')\n",
    "ax5.set_title('Binary diff Image', fontsize=15)\n",
    "ax6.imshow(color_diff_binary)\n",
    "ax6.set_title('Colored diff Image', fontsize=15)\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "\n",
    "# plt.savefig(\"output_images/2_3_distortion_comparisson.png\")"
   ]
  },
  {
   "source": [
    "## 2.4. Warp perspective calibration with given straight lane lines images"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start camera calibration...\n",
      "Camera calibrated! RMS re-projection error (retval): 1.0298153371058965\n",
      "\n",
      "src_vertices:\n",
      "\n",
      "[[ 183.  720.]\n",
      " [ 593.  450.]\n",
      " [ 687.  450.]\n",
      " [1097.  720.]]\n",
      "\n",
      "dst_vertices:\n",
      "\n",
      "[[ 280.  720.]\n",
      " [ 280.    0.]\n",
      " [1000.    0.]\n",
      " [1000.  720.]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate camera calibration\n",
    "ret, mtx, dist = cal_camera_calibration()\n",
    "\n",
    "# Read a straight lane image\n",
    "img = mpimg.imread(\"test_images/straight_lines1.jpg\")\n",
    "img2 = mpimg.imread(\"test_images/straight_lines2.jpg\")\n",
    "\n",
    "# Undistort image\n",
    "img_undistorted = cal_undistort(img, mtx, dist)\n",
    "img_undistorted2 = cal_undistort(img2, mtx, dist)\n",
    "\n",
    "# Warp perspective auxiliar variables to compute source and destination vertices to be used by cal_perspective_matrix()\n",
    "dst_horizontal_offset = 360\n",
    "src_roi_upper = 450\n",
    "src_horizontal_offset_upper = 47\n",
    "src_horizontal_offset_lower = 457\n",
    "src_horizontal_drift_upper_l = 0\n",
    "src_horizontal_drift_upper_r = 0\n",
    "src_horizontal_drift_lower_l = 0\n",
    "src_horizontal_drift_lower_r = 0\n",
    "\n",
    "# Calculate source and destination vertices\n",
    "src_vertices, dst_vertices, M = cal_perspective_matrix(img.shape[1],img.shape[0])\n",
    "\n",
    "# Apply perspective transform to the undistorted image\n",
    "img_warped = cal_perspective(img_undistorted,M)\n",
    "img_warped2 = cal_perspective(img_undistorted2,M)\n",
    "\n",
    "\n",
    "for i in range(0,len(src_vertices)):\n",
    "    pos1 = (int(src_vertices[i][0]),int(src_vertices[i][1]))\n",
    "    pos2 = (int(src_vertices[i-1][0]),int(src_vertices[i-1][1]))\n",
    "    cv2.line(img_undistorted,pos1,pos2,(255,150,150),4)\n",
    "    cv2.line(img_undistorted2,pos1,pos2,(255,150,150),4)\n",
    "    cv2.circle(img_undistorted,pos1,5,(255,0,0),-1)\n",
    "    cv2.circle(img_undistorted2,pos1,5,(255,0,0),-1)\n",
    "\n",
    "for dv in dst_vertices:\n",
    "    pos = (int(dv[0]),int(dv[1]))\n",
    "    cv2.circle(img_undistorted,pos,10,(0,255,0),-1)\n",
    "    cv2.circle(img_undistorted2,pos,10,(0,255,0),-1)\n",
    "\n",
    "cv2.line(img_warped,(310,0),(310,img_warped.shape[0]),(255,0,0),8)\n",
    "cv2.line(img_warped,(1010,0),(1010,img_warped.shape[0]),(255,0,0),8)\n",
    "cv2.line(img_warped2,(310,0),(310,img_warped.shape[0]),(255,0,0),8)\n",
    "cv2.line(img_warped2,(1010,0),(1010,img_warped.shape[0]),(255,0,0),8)\n",
    "\n",
    "# Plot original image and the undistorted image\n",
    "f, ((ax1, ax2,ax3),(ax4, ax5,ax6)) = plt.subplots(2, 3, figsize=(24, 9))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=15)\n",
    "ax2.imshow(img_undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=15)\n",
    "ax3.imshow(img_warped)\n",
    "ax3.set_title('Warped Image', fontsize=15)\n",
    "ax4.imshow(img2)\n",
    "ax4.set_title('Original Image', fontsize=15)\n",
    "ax5.imshow(img_undistorted2)\n",
    "ax5.set_title('Undistorted Image', fontsize=15)\n",
    "ax6.imshow(img_warped2)\n",
    "ax6.set_title('Warped Image', fontsize=15)\n",
    "plt.subplots_adjust(left=0.0, right=1.0, top=0.9, bottom=0.0)\n",
    "\n",
    "# plt.savefig(\"output_images/2_4_perspective_transform_calibration.png\")\n",
    "\n",
    "print(\"\\nsrc_vertices:\\n\")\n",
    "print(src_vertices)\n",
    "print(\"\\ndst_vertices:\\n\")\n",
    "print(dst_vertices)"
   ]
  },
  {
   "source": [
    "## 2.5. Polynomial fit methods\n",
    "- Calculate the histogram of all columns in the lower half of the warped image to get the left and right side peak,\n",
    "- Calculate the lane lines by Sliding Window method\n",
    "- Calculate the lane lines by Search Around method"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Start camera calibration...\n",
      "Camera calibrated! RMS re-projection error (retval): 1.0298153371058965\n",
      "\n",
      "leftx_base: 329\n",
      "rightx_base: 1087\n"
     ]
    }
   ],
   "source": [
    "# Calculate camera calibration\n",
    "ret, mtx, dist = cal_camera_calibration()\n",
    "\n",
    "# Read a straight lane image\n",
    "img = mpimg.imread(\"test_images/test1.jpg\")\n",
    "\n",
    "# Undistort image\n",
    "img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "# Apply color and gradient threshold\n",
    "img_und_thresholded = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"RGB\")[0]\n",
    "\n",
    "# Calculate source and destination vertices\n",
    "src_vertices, dst_vertices, M = cal_perspective_matrix(img.shape[1],img.shape[0])\n",
    "\n",
    "# Apply perspective transform to the undistorted image\n",
    "img_warped = cal_perspective(img_und_thresholded,M)\n",
    "\n",
    "# Create histogram of image binary activations\n",
    "histogram = np.sum(img_warped[img_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "# Find the peak of the left and right halves of the histogram\n",
    "midpoint = np.int(histogram.shape[0]//2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "print(\"\\nleftx_base: {}\".format(leftx_base))\n",
    "print(\"rightx_base: {}\".format(rightx_base))\n",
    "\n",
    "# Plot warped image and the calculated histogram\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15,5))\n",
    "ax1.imshow(img_warped, cmap='gray')\n",
    "ax1.set_title('Warped Image', fontsize=15,)\n",
    "ax2.plot(histogram)\n",
    "ax2.set_title('Lower Half Histogram', fontsize=15)\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.90, bottom=0.1)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"output_images/2_5_warped_histogram.png\")\n",
    "\n",
    "# Wait 2 seconds and clear plot area\n",
    "plt.pause(2.0)\n",
    "plt.clf()\n",
    "\n",
    "# Reset moving averages\n",
    "reset_ma()\n",
    "\n",
    "# Calculate the Sliding window method to find lane lines \n",
    "left_fit, right_fit, left_fitx, right_fitx, fity, img_warped_poly_fit = cal_sliding_window(img_warped,nwindows=nwindows,margin=margin,minpix=minpix)\n",
    "\n",
    "plt.imshow(img_warped_poly_fit)\n",
    "plt.title(\"Sliding Window Method\", fontsize=15)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"output_images/2_5_sliding_window.png\")\n",
    "\n",
    "# Wait 2 seconds and clear plot area\n",
    "plt.pause(2.0)\n",
    "plt.clf()\n",
    "\n",
    "# Calculate the Search Around method to find lane lines \n",
    "left_fit, right_fit, left_fitx, right_fitx, fity, img_warped_poly_fit = cal_search_around_poly(img_warped, margin_sa=margin_sa)\n",
    "\n",
    "plt.title(\"Search Around Method\", fontsize=15)\n",
    "plt.imshow(img_warped_poly_fit)\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(\"output_images/2_5_search_around.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('cv': virtualenvwrapper)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "6a0b733e851c76961a3549792236d53668940e76a299dd69e80c674f6368f9f8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}