{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Lane Finding Project\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "* Apply a distortion correction to raw images.\n",
    "* Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "* Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "* Detect lane pixels and fit to find the lane boundary.\n",
    "* Determine the curvature of the lane and vehicle position with respect to center.\n",
    "* Warp the detected lane boundaries back onto the original image.\n",
    "* Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "source": [
    "# 0. Helper Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_image_arr(img_list,max_columns,title_list=[],resize_factor = 0.4):\n",
    "    \n",
    "    # Check if is enough images to complete the last img composition line and add blank image if needed\n",
    "    if len(img_list) % max_columns > 0:\n",
    "        blk = np.copy(img)*0\n",
    "        for i in range(max_columns - (len(img_list) % max_columns)):\n",
    "            img_list.append(blk)\n",
    "            title_list.append(\"\")\n",
    "\n",
    "    img_list_2d=[]\n",
    "\n",
    "    for i in range(0,len(img_list)):\n",
    "        # Check if its not a colored image and stack it like a 3 channel color image\n",
    "        if len(img_list[i].shape) == 2:\n",
    "            img_list[i] = np.dstack((img_list[i], img_list[i], img_list[i]))\n",
    "            \n",
    "            # if its a binary, then scale to 255\n",
    "            if np.max(img_list[i]) == 1:\n",
    "                img_list[i] = img_list[i]*255\n",
    "        \n",
    "        # Add image name on the top left corner\n",
    "        if len(title_list)>0:\n",
    "            cv2.putText(img_list[i],title_list[i],(10,40),cv2.FONT_HERSHEY_SIMPLEX,1.5,(0,0,255),3,cv2.LINE_AA)\n",
    "\n",
    "        # if it is the first image of a line, add an empty list to be populated next with following images\n",
    "        if (i % max_columns) == 0:\n",
    "            img_list_2d.append([])\n",
    "        img_list_2d[int(i/max_columns)].append(img_list[i])\n",
    "\n",
    "    # Concatenate images making a composition of fixed number of images in width\n",
    "    composed_img = cv2.vconcat([cv2.hconcat(im_list_h) for im_list_h in img_list_2d])\n",
    "    \n",
    "    # Resize whole composition\n",
    "    composed_img_resized = cv2.resize(composed_img, (int(composed_img.shape[1]*resize_factor),int(composed_img.shape[0]*resize_factor)), interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return composed_img_resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "hls_threshold=(160, 255)\n",
    "sobel_threshold=(15, 100)"
   ]
  },
  {
   "source": [
    "# 1. Compute the camera calibration matrix and distortion coefficients using a set of chessboard images."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mtx:\n[[1.15777930e+03 0.00000000e+00 6.67111054e+02]\n [0.00000000e+00 1.15282291e+03 3.86128938e+02]\n [0.00000000e+00 0.00000000e+00 1.00000000e+00]]\ndist:\n[[-0.24688775 -0.02373132 -0.00109842  0.00035108 -0.00258571]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib qt\n",
    "\n",
    "# prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "    # cv2.imshow('img',img)\n",
    "    # cv2.waitKey(100)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Get calibration image shape\n",
    "cal_img = cv2.imread(images[0])\n",
    "cal_img_shape = cal_img.shape[1::-1]\n",
    "\n",
    "# Calculate camera calibration params\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, cal_img_shape, None, None)\n",
    "\n",
    "print(\"mtx:\\n\"+str(mtx))\n",
    "print(\"dist:\\n\"+str(dist))"
   ]
  },
  {
   "source": [
    "## 1.1. Define `cal_undistort` function to apply a distortion correction to given images with parameters previously calculated"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns undistorted image using the camera intrinsic and extrinsic parameters previously calculated\n",
    "def cal_undistort(img, mtx, dist):\n",
    "    undist = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Test camera calibration and distortion correction with a chessboard image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read an chessboard image\n",
    "img = mpimg.imread(images[9])\n",
    "\n",
    "# Undistort image\n",
    "undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "# Plot original image and the undistorted image\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=50)\n",
    "ax2.imshow(undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=50)\n",
    "plt.subplots_adjust(left=0.0, right=1.0, top=0.9, bottom=0.0)\n",
    "\n",
    "# plt.savefig(\"output_images/camera_calibration.png\")"
   ]
  },
  {
   "source": [
    "# 2. Color and Gradient Threshold"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 2.1 Define `cal_threshold` function to create a thresholded binary image by applying color transform to HLS colorspace, gradient in x with Sobel operator and threshold combination."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the combined binary image of Sobel and S Channel thresholded\n",
    "def cal_threshold(img,hls_threshold=(170, 255),sobel_threshold=(20, 100),color_space=\"RGB\"):\n",
    "\n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    if color_space == \"RGB\":\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    else:\n",
    "        hls = cv2.cvtColor(img, cv2.COLOR_BGR2HLS)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "\n",
    "    # Sobel x\n",
    "    sobelx = cv2.Sobel(s_channel, cv2.CV_64F, 1, 0) # Take the derivative in x\n",
    "    abs_sobelx = np.absolute(sobelx) # Absolute x derivative to accentuate lines away from horizontal\n",
    "    scaled_sobel = np.uint8(255*abs_sobelx/np.max(abs_sobelx))\n",
    "    \n",
    "    # Threshold x gradient\n",
    "    sxbinary = np.zeros_like(scaled_sobel)\n",
    "    sxbinary[(scaled_sobel >= sobel_threshold[0]) & (scaled_sobel <= sobel_threshold[1])] = 1\n",
    "    \n",
    "    # Threshold color channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= hls_threshold[0]) & (s_channel <= hls_threshold[1])] = 1\n",
    "\n",
    "    # Stack each channel\n",
    "    color_binary = np.dstack(( np.zeros_like(sxbinary), sxbinary, s_binary)) * 255\n",
    "\n",
    "    # Combine the two binary thresholds\n",
    "    combined_binary = np.zeros_like(sxbinary)\n",
    "    combined_binary[(s_binary == 1) | (sxbinary == 1)] = 1\n",
    "\n",
    "    return combined_binary,sxbinary,s_binary,h_channel,l_channel,s_channel"
   ]
  },
  {
   "source": [
    "## 2.2. Dynamicly Calibrate `cal_threshold()` "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calibrated threshold params:\n  hls_threshold: (160,255)\n  sobel_threshold: (15,100)\n"
     ]
    }
   ],
   "source": [
    "# Make a list of test images\n",
    "test_images = glob.glob('test_images/*.jpg')\n",
    "test_images_index = 0\n",
    "\n",
    "# Create a window with trackbars and callback functions bolow to handle when values are changed\n",
    "cv2.namedWindow(\"Threshold Calibration\")\n",
    "\n",
    "def on_hls_th_l(val):\n",
    "    global hls_threshold\n",
    "    hls_threshold = (val,hls_threshold[1])\n",
    "\n",
    "def on_hls_th_u(val):\n",
    "    global hls_threshold\n",
    "    hls_threshold = (hls_threshold[0],val)\n",
    "\n",
    "def on_sobel_th_l(val):\n",
    "    global sobel_threshold\n",
    "    sobel_threshold = (val,sobel_threshold[1])\n",
    "\n",
    "def on_sobel_th_u(val):\n",
    "    global sobel_threshold\n",
    "    sobel_threshold = (sobel_threshold[0],val)\n",
    "\n",
    "cv2.createTrackbar(\"Color Threshold Lower\",\"Threshold Calibration\",hls_threshold[0],255,on_hls_th_l)\n",
    "cv2.createTrackbar(\"Color Threshold Upper\",\"Threshold Calibration\",hls_threshold[1],255,on_hls_th_u)\n",
    "cv2.createTrackbar(\"Sobel Threshold Lower\",\"Threshold Calibration\",sobel_threshold[0],255,on_sobel_th_l)\n",
    "cv2.createTrackbar(\"Sobel Threshold Upper\",\"Threshold Calibration\",sobel_threshold[1],255,on_sobel_th_u)\n",
    "\n",
    "while True:\n",
    "    img_list=[]\n",
    "\n",
    "    # Read image of current index\n",
    "    img = cv2.imread(test_images[test_images_index])\n",
    "\n",
    "    # Undistort image\n",
    "    img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "    img_und_thresholded,sxbinary,s_binary,h_channel,l_channel,s_channel = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"BGR\")\n",
    "\n",
    "    img_list.append(img)\n",
    "    img_list.append(img_undistorted)\n",
    "    img_list.append(np.zeros_like(img))\n",
    "    img_list.append(h_channel)\n",
    "    img_list.append(l_channel)\n",
    "    img_list.append(s_channel)\n",
    "    img_list.append(sxbinary)\n",
    "    img_list.append(s_binary)\n",
    "    img_list.append(img_und_thresholded)\n",
    "\n",
    "    title_list = [\"[{}]Original\".format(test_images[test_images_index].split('/')[1]),\"Undistorted\",\"\",\"H Channel\",\"L Channel\",\"S Channel\",\"Sobel Threshold\",\"S Channel Threshold\",\"Combined Threshold\"]\n",
    "    img_compostion = compose_image_arr(img_list,3,title_list=title_list,resize_factor=0.40)\n",
    "\n",
    "    cv2.imshow(\"Threshold Calibration\",img_compostion)\n",
    "    key = cv2.waitKey(200) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('w'):\n",
    "        test_images_index += 1\n",
    "        if(test_images_index >= len(test_images)):\n",
    "            test_images_index = 0\n",
    "    elif key == ord('e'):\n",
    "        test_images_index -= 1\n",
    "        if(test_images_index < 0):\n",
    "            test_images_index = len(test_images)-1\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"output_images/image_thresholds_cv2.png\",img_compostion)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(\"Calibrated threshold params:\")\n",
    "print(\"  hls_threshold: ({},{})\".format(hls_threshold[0],hls_threshold[1]))\n",
    "print(\"  sobel_threshold: ({},{})\".format(sobel_threshold[0],sobel_threshold[1]))"
   ]
  },
  {
   "source": [
    "## 2.2. Test `cal_threshold()` with test images and compare original with undistorted images processed"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read an chessboard image\n",
    "img = mpimg.imread(\"test_images/test1.jpg\")\n",
    "\n",
    "# Undistort image\n",
    "img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "# Apply color and gradient threshold\n",
    "img_thresholded = cal_threshold(img)[0]\n",
    "img_und_thresholded = cal_threshold(img_undistorted)[0]\n",
    "\n",
    "# Plot original image, the undistorted image and the respectives thresholded images\n",
    "f, ((ax1, ax2), (ax3,ax4),(ax5,ax6)) = plt.subplots(3,2, figsize=(12, 11))\n",
    "# f.tight_layout()\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=15)\n",
    "ax2.imshow(img_undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=15)\n",
    "ax3.imshow(img_thresholded, cmap='gray')\n",
    "ax3.set_title('Thresholded Image', fontsize=15)\n",
    "ax4.imshow(img_und_thresholded, cmap='gray')\n",
    "ax4.set_title('Thresholded Undistorted Image', fontsize=15)\n",
    "\n",
    "# Check differences between the original and undistorted binary thresholds\n",
    "diff_binary = np.zeros_like(img_thresholded)\n",
    "diff_binary[((img_thresholded == 0) & (img_und_thresholded == 1)) | ((img_thresholded == 1) & (img_und_thresholded == 0))] = 1\n",
    "# diff_binary[(img_thresholded == 0) & (img_und_thresholded == 1)] = 1\n",
    "color_diff_binary = np.dstack(( img_thresholded,img_und_thresholded,np.zeros_like(img_und_thresholded))) * 255\n",
    "\n",
    "ax5.imshow(diff_binary, cmap='gray')\n",
    "ax5.set_title('Binary diff Image', fontsize=15)\n",
    "ax6.imshow(color_diff_binary)\n",
    "ax6.set_title('Colored diff Image', fontsize=15)\n",
    "\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "\n",
    "# plt.savefig(\"output_images/image_thresholds.png\")"
   ]
  },
  {
   "source": [
    "# 3. Perspective transform to rectify binary image (\"birds-eye view\")."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 3.1. Define `cal_perspective()` to return a perspective transform of the lane region"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_perspective(img_d,src,dst):\n",
    "    \n",
    "    img_size = None\n",
    "    if len(img_d.shape) > 2:\n",
    "        img_size = img_d.shape[1::-1]\n",
    "    else:\n",
    "        img_size = img_d.shape[::-1]\n",
    "        img_d = img_d*255\n",
    "    # Given src and dst points, calculate the perspective transform matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    \n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped = cv2.warpPerspective(img_d, M, img_size)\n",
    "\n",
    "    return warped"
   ]
  },
  {
   "source": [
    "## 3.2. Define source and destination vertices to calibrate `cal_perspective()` with a straight lane image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Auxiliar variables to compute source and destination vertices to be used by cal_perspective()\n",
    "# These vertices represent the lane region of interest, assuming that the camera is at the center of the vehicle\n",
    "src_roi_upper = 450\n",
    "src_roi_lower = img_undistorted.shape[0]\n",
    "\n",
    "src_horizontal_center_x = img_undistorted.shape[1]/2 +13\n",
    "src_horizontal_offset_upper = 47\n",
    "src_horizontal_offset_lower = 470\n",
    "src_horizontal_drift_upper_l = -15\n",
    "src_horizontal_drift_upper_r = -11\n",
    "src_horizontal_drift_lower_l = 0\n",
    "src_horizontal_drift_lower_r = 0\n",
    "\n",
    "dst_horizontal_offset = 360\n",
    "\n",
    "src_vertices = np.array(\n",
    "   [[src_horizontal_center_x - src_horizontal_offset_lower + src_horizontal_drift_lower_l , src_roi_lower],\n",
    "    [src_horizontal_center_x - src_horizontal_offset_upper + src_horizontal_drift_upper_l , src_roi_upper], \n",
    "    [src_horizontal_center_x + src_horizontal_offset_upper + src_horizontal_drift_upper_r , src_roi_upper], \n",
    "    [src_horizontal_center_x + src_horizontal_offset_lower + src_horizontal_drift_lower_r , src_roi_lower]],\n",
    "    np.float32)\n",
    "\n",
    "# Define destination vertices to warp\n",
    "dst_vertices = np.array(\n",
    "   [[src_horizontal_center_x - dst_horizontal_offset, img_undistorted.shape[0]],\n",
    "    [src_horizontal_center_x - dst_horizontal_offset, 0],\n",
    "    [src_horizontal_center_x + dst_horizontal_offset, 0], \n",
    "    [src_horizontal_center_x + dst_horizontal_offset, img_undistorted.shape[0]]],\n",
    "    np.float32)\n",
    "\n",
    "M = cv2.getPerspectiveTransform(src_vertices, dst_vertices)\n",
    "M_inv = cv2.getPerspectiveTransform(dst_vertices, src_vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a straight lane image\n",
    "img = mpimg.imread(\"test_images/straight_lines1.jpg\")\n",
    "img2 = mpimg.imread(\"test_images/straight_lines2.jpg\")\n",
    "\n",
    "# Undistort image\n",
    "img_undistorted = cal_undistort(img, mtx, dist)\n",
    "img_undistorted2 = cal_undistort(img2, mtx, dist)\n",
    "\n",
    "# Apply perspective transform to the undistorted image\n",
    "img_warped = cal_perspective(img_undistorted,src_vertices,dst_vertices)\n",
    "img_warped2 = cal_perspective(img_undistorted2,src_vertices,dst_vertices)\n",
    "\n",
    "\n",
    "for i in range(0,len(src_vertices)):\n",
    "    pos1 = (int(src_vertices[i][0]),int(src_vertices[i][1]))\n",
    "    pos2 = (int(src_vertices[i-1][0]),int(src_vertices[i-1][1]))\n",
    "    cv2.line(img_undistorted,pos1,pos2,(255,150,150),4)\n",
    "    cv2.line(img_undistorted2,pos1,pos2,(255,150,150),4)\n",
    "    cv2.circle(img_undistorted,pos1,5,(255,0,0),-1)\n",
    "    cv2.circle(img_undistorted2,pos1,5,(255,0,0),-1)\n",
    "\n",
    "for dv in dst_vertices:\n",
    "    pos = (int(dv[0]),int(dv[1]))\n",
    "    cv2.circle(img_undistorted,pos,10,(0,255,0),-1)\n",
    "    cv2.circle(img_undistorted2,pos,10,(0,255,0),-1)\n",
    "\n",
    "cv2.line(img_warped,(330,0),(330,img_warped.shape[0]),(255,0,0),8)\n",
    "cv2.line(img_warped,(980,0),(980,img_warped.shape[0]),(255,0,0),8)\n",
    "cv2.line(img_warped2,(330,0),(330,img_warped.shape[0]),(255,0,0),8)\n",
    "cv2.line(img_warped2,(980,0),(980,img_warped.shape[0]),(255,0,0),8)\n",
    "\n",
    "# Plot original image and the undistorted image\n",
    "f, ((ax1, ax2,ax3),(ax4, ax5,ax6)) = plt.subplots(2, 3, figsize=(24, 9))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=15)\n",
    "ax2.imshow(img_undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=15)\n",
    "ax3.imshow(img_warped)\n",
    "ax3.set_title('Warped Image', fontsize=15)\n",
    "ax4.imshow(img2)\n",
    "ax4.set_title('Original Image', fontsize=15)\n",
    "ax5.imshow(img_undistorted2)\n",
    "ax5.set_title('Undistorted Image', fontsize=15)\n",
    "ax6.imshow(img_warped2)\n",
    "ax6.set_title('Warped Image', fontsize=15)\n",
    "plt.subplots_adjust(left=0.0, right=1.0, top=0.9, bottom=0.0)\n",
    "\n",
    "# plt.savefig(\"output_images/perspective_transform.png\")"
   ]
  },
  {
   "source": [
    "## 3.3. Apply a perspective transform to rectify binary image from thresholding step to get the \"birds-eye view\" image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a straight lane image\n",
    "img = mpimg.imread(\"test_images/test1.jpg\")\n",
    "\n",
    "# Undistort image\n",
    "img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "# Apply color and gradient threshold\n",
    "img_und_thresholded = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"RGB\")[0]\n",
    "\n",
    "# Source and destination vertices previously defined\n",
    "# Apply perspective transform to the undistorted image\n",
    "img_warped = cal_perspective(img_und_thresholded,src_vertices,dst_vertices)\n",
    "\n",
    "# Draw vertices\n",
    "for i in range(0,len(src_vertices)):\n",
    "    pos1 = (int(src_vertices[i][0]),int(src_vertices[i][1]))\n",
    "    pos2 = (int(src_vertices[i-1][0]),int(src_vertices[i-1][1]))\n",
    "    cv2.line(img_undistorted,pos1,pos2,(255,150,150),3)\n",
    "    cv2.circle(img_undistorted,pos1,5,(255,0,0),-1)\n",
    "\n",
    "img_warped = np.dstack((img_warped,img_warped,img_warped))\n",
    "\n",
    "# Plot original image and the undistorted image\n",
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 9))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original Image', fontsize=15)\n",
    "ax2.imshow(img_undistorted)\n",
    "ax2.set_title('Undistorted Image', fontsize=15)\n",
    "ax3.imshow(img_und_thresholded, cmap='gray')\n",
    "ax3.set_title('Thresholded Undistorted Image', fontsize=15)\n",
    "ax4.imshow(img_warped)\n",
    "ax4.set_title('Warped Image', fontsize=15)\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
    "\n",
    "# plt.savefig(\"output_images/perspective_transform.png\")"
   ]
  },
  {
   "source": [
    "## 4. Detect lane pixels and fit to find the lane boundary"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We are going to implement the Sliding window method to find the lane lines and fit a polinomial line to them"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.1 Calculate the histogram of all the columns in the lower half of the warped image and get the left and right side peak"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa97c00d390>]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Read a straight lane image\n",
    "img = mpimg.imread(\"test_images/test1.jpg\")\n",
    "\n",
    "# Undistort image\n",
    "img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "# Apply color and gradient threshold\n",
    "img_und_thresholded = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"RGB\")[0]\n",
    "\n",
    "# Source and destination vertices previously defined\n",
    "# Apply perspective transform to the undistorted image\n",
    "img_warped = cal_perspective(img_und_thresholded,src_vertices,dst_vertices)\n",
    "\n",
    "# Create histogram of image binary activations\n",
    "histogram = np.sum(img_warped[img_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "# Find the peak of the left and right halves of the histogram\n",
    "midpoint = np.int(histogram.shape[0]//2)\n",
    "leftx_base = np.argmax(histogram[:midpoint])\n",
    "rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "# Visualize the resulting histogram\n",
    "plt.plot(histogram)"
   ]
  },
  {
   "source": [
    "## 4. Detect lane pixels and fit to find the lane boundary."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 4.1 Define common global variables and helper functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPERPARAMETERS\n",
    "# Choose the number of sliding windows\n",
    "nwindows = 9\n",
    "# Set the width of the windows +/- margin\n",
    "margin = 100\n",
    "# Set minimum number of pixels found to recenter window\n",
    "minpix = 50\n",
    "# The margin width around the previous polynomial to search\n",
    "margin_sa = 100\n",
    "\n",
    "# Moving average length\n",
    "moving_avg_max_count = 5\n",
    "\n",
    "# Lanes polynomial Fit variables array\n",
    "left_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "right_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset lanes polynomial fit average arrays\n",
    "def reset_ma():\n",
    "    global left_fit_avg_arr\n",
    "    global right_fit_avg_arr\n",
    "    left_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "    right_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "\n",
    "# Return both lane lines sides array without empty values\n",
    "def get_fit_avg_arr_filtered():\n",
    "    left_fit_avg_arr_filtered = [ arr for arr in left_fit_avg_arr if len(arr)>0 ]\n",
    "    right_fit_avg_arr_filtered = [ arr for arr in right_fit_avg_arr if len(arr)>0 ]\n",
    "\n",
    "    return left_fit_avg_arr_filtered, right_fit_avg_arr_filtered"
   ]
  },
  {
   "source": [
    "## 4.2.1 Define `cal_sliding_window()` function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_sliding_window(img_warped,nwindows=9,margin=100,minpix=50,draw=True):\n",
    "\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(img_warped[img_warped.shape[0]//2:,:], axis=0)\n",
    "\n",
    "    # Create an output image to draw on and visualize the result\n",
    "    img_binary_out = np.dstack((img_warped, img_warped, img_warped))\n",
    "\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Set height of windows - based on nwindows above and image shape\n",
    "    window_height = np.int(img_warped.shape[0]//nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = img_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated later for each window in nwindows\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = img_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        # Draw the windows on the visualization image\n",
    "        if draw:\n",
    "            cv2.rectangle(img_binary_out,(win_xleft_low,win_y_low),\n",
    "            (win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "            cv2.rectangle(img_binary_out,(win_xright_low,win_y_low),\n",
    "            (win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window #\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "        (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices (previously was a list of lists of pixels)\n",
    "    try:\n",
    "        left_lane_inds = np.concatenate(left_lane_inds)\n",
    "        right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    except ValueError:\n",
    "        # Avoids an error if the above is not implemented fully\n",
    "        pass\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    left_fit, right_fit, left_fitx, right_fitx, fity = cal_fit_polynomial(img_warped.shape[0],leftx,lefty,rightx,righty,clear_ma=True)\n",
    "\n",
    "    if draw:\n",
    "        # Color in left and right line pixels\n",
    "        img_binary_out[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        img_binary_out[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Draw the left and right polynomials on top of the img_binary_out image\n",
    "        if len(left_fitx) > 0 and len(right_fitx) > 0 :\n",
    "            lane_l = np.dstack((left_fitx, fity))[0]\n",
    "            lane_r = np.dstack((right_fitx, fity))[0]\n",
    "            cv2.polylines(img_binary_out,np.int32([lane_l]),False,(0,255,255),thickness=3)\n",
    "            cv2.polylines(img_binary_out,np.int32([lane_r]),False,(0,255,255),thickness=3)\n",
    "\n",
    "    return left_fit, right_fit, left_fitx, right_fitx, fity, img_binary_out\n"
   ]
  },
  {
   "source": [
    "## 4.2.2 Define `cal_search_around_poly()` function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_search_around_poly(img_warped, margin_sa=100, draw=True):\n",
    "\n",
    "    # Create an image to draw on and an image to show the selection window\n",
    "    img_binary_out = np.dstack((img_warped, img_warped, img_warped))*255\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = img_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "\n",
    "    # Calculate the currente lane lines fit averages\n",
    "    left_fit_avg_arr_filtered = [ arr for arr in left_fit_avg_arr if len(arr)>0 ]\n",
    "    right_fit_avg_arr_filtered = [ arr for arr in right_fit_avg_arr if len(arr)>0 ]\n",
    "\n",
    "    left_fit_avg = np.array([])\n",
    "    right_fit_avg = np.array([])\n",
    "\n",
    "    if len(left_fit_avg_arr_filtered)>0 and len(right_fit_avg_arr_filtered)>0:\n",
    "        left_fit_avg = np.mean(left_fit_avg_arr_filtered,axis=0)\n",
    "        right_fit_avg = np.mean(right_fit_avg_arr_filtered,axis=0)\n",
    "    \n",
    "    # If any average arrays is empty, then return with empty values. This might be an error durting calibration\n",
    "    else:\n",
    "        return left_fit_avg, right_fit_avg, np.array([]), np.array([]), np.array([]), img_binary_out\n",
    "\n",
    "    # Set the area of search based on activated x-values\n",
    "    left_lane_inds = ((nonzerox > (left_fit_avg[0]*(nonzeroy**2) + left_fit_avg[1]*nonzeroy + \n",
    "                    left_fit_avg[2] - margin_sa)) & (nonzerox < (left_fit_avg[0]*(nonzeroy**2) + \n",
    "                    left_fit_avg[1]*nonzeroy + left_fit_avg[2] + margin_sa)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit_avg[0]*(nonzeroy**2) + right_fit_avg[1]*nonzeroy + \n",
    "                    right_fit_avg[2] - margin_sa)) & (nonzerox < (right_fit_avg[0]*(nonzeroy**2) + \n",
    "                    right_fit_avg[1]*nonzeroy + right_fit_avg[2] + margin_sa)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "\n",
    "    # Calculate the new fit polynomial\n",
    "    left_fit, right_fit, left_fitx, right_fitx, fity = cal_fit_polynomial(img_warped.shape[0],leftx,lefty,rightx,righty)\n",
    "\n",
    "    if draw:\n",
    "        window_img = np.zeros_like(img_binary_out)\n",
    "\n",
    "        # Color in left and right line pixels\n",
    "        img_binary_out[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        img_binary_out[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin_sa, fity]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin_sa, \n",
    "                                fity])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin_sa, fity]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin_sa, \n",
    "                                fity])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        img_binary_out = cv2.addWeighted(img_binary_out, 1, window_img, 0.3, 0)\n",
    "\n",
    "        # Draw the left and right polynomials on top of the img_binary_out image\n",
    "        if len(left_fitx) > 0 and len(right_fitx) > 0 :\n",
    "            lane_l = np.dstack((left_fitx, fity))[0]\n",
    "            lane_r = np.dstack((right_fitx, fity))[0]\n",
    "            cv2.polylines(img_binary_out,np.int32([lane_l]),False,(0,255,255),thickness=3)\n",
    "            cv2.polylines(img_binary_out,np.int32([lane_r]),False,(0,255,255),thickness=3)\n",
    "    \n",
    "    \n",
    "    return left_fit, right_fit, left_fitx, right_fitx, fity, img_binary_out"
   ]
  },
  {
   "source": [
    "## 4.2.3 Define `cal_fit_polynomial()` function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_fit_polynomial(img_size_y, leftx, lefty, rightx, righty, clear_ma=False):\n",
    "    global left_fit_avg_arr\n",
    "    global right_fit_avg_arr\n",
    "\n",
    "    # Reset lanes polynomial fit average arrays if requested\n",
    "    if clear_ma:\n",
    "        left_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "        right_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "\n",
    "    # Calculate new fit polynomial values\n",
    "    try:\n",
    "        left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    except TypeError:\n",
    "        left_fit = []\n",
    "    \n",
    "    try:\n",
    "        right_fit = np.polyfit(righty, rightx, 2)\n",
    "    except TypeError:\n",
    "        right_fit = []\n",
    "\n",
    "    # Append the new value to the moving average array\n",
    "    left_fit_avg_arr.append(left_fit) \n",
    "    right_fit_avg_arr.append(right_fit) \n",
    "\n",
    "    # # Append the new value to the moving average array\n",
    "    # left_fit_avg_arr.append(left_fit) \n",
    "    # right_fit_avg_arr.append(right_fit) \n",
    "\n",
    "    # left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    # right_fit = np.polyfit(righty, rightx, 2)\n",
    "    # if len(left_fit)>0:\n",
    "    #     left_fit_avg_arr.append(left_fit) \n",
    "\n",
    "    # if len(right_fit)>0:\n",
    "    #     right_fit_avg_arr.append(right_fit) \n",
    "\n",
    "    # Remove first (older) value and trim array to max moving average elements\n",
    "    left_fit_avg_arr = left_fit_avg_arr[1:moving_avg_max_count+1]\n",
    "    right_fit_avg_arr = right_fit_avg_arr[1:moving_avg_max_count+1]\n",
    "    \n",
    "    left_fit_avg_arr_filtered = [ arr for arr in left_fit_avg_arr if len(arr)>0 ]\n",
    "    right_fit_avg_arr_filtered = [ arr for arr in right_fit_avg_arr if len(arr)>0 ]\n",
    "\n",
    "    lanes_fit = [left_fit_avg_arr_filtered,right_fit_avg_arr_filtered]\n",
    "    lanes_fit_avg = [np.array([]),np.array([])]\n",
    "    lanes_fitx = [np.array([]),np.array([])]\n",
    "\n",
    "    # Generate x and y values for plotting\n",
    "    fity = np.linspace(0, img_size_y-1, img_size_y)\n",
    "\n",
    "    # Calculate average fit and x values for each lane side\n",
    "    for i in range(len(lanes_fit)):\n",
    "        if len(lanes_fit[i]) > 0:\n",
    "            try:\n",
    "                lanes_fit_avg[i] = np.mean(lanes_fit[i],axis=0)\n",
    "                lanes_fitx[i] = lanes_fit_avg[i][0]*fity**2 + lanes_fit_avg[i][1]*fity + lanes_fit_avg[i][2]\n",
    "            except TypeError:\n",
    "                print('cal_fit_polynomial(): Failed to fit {} line!'.format('left' if i == 0 else 'right'))\n",
    "                lanes_fitx[i] = np.array([])\n",
    "\n",
    "    return lanes_fit_avg[0], lanes_fit_avg[1], lanes_fitx[0], lanes_fitx[1], fity\n"
   ]
  },
  {
   "source": [
    "## 4.3.1. Test with single test image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to next image index and reset moving average\n",
    "test_images_index += 1 if test_images_index < (len(test_images)-1) else -(len(test_images)-1)\n",
    "reset_ma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa97bddb390>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "# Read image of current index\n",
    "img = cv2.imread(test_images[test_images_index])\n",
    "\n",
    "# Undistort image\n",
    "img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "img_und_thresholded = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"BGR\")[0]\n",
    "\n",
    "# Apply perspective transform to the undistorted thresholded image\n",
    "img_warped = cal_perspective(img_und_thresholded,src_vertices,dst_vertices)\n",
    "\n",
    "left_fit_avg_arr_filtered, right_fit_avg_arr_filtered = get_fit_avg_arr_filtered()\n",
    "\n",
    "# If both lane lines fit array arent empty, then search around\n",
    "if len(left_fit_avg_arr_filtered) > 0 and len(right_fit_avg_arr_filtered) > 0 :\n",
    "    left_fit, right_fit, left_fitx, right_fitx, fity, img_binary_out = cal_search_around_poly(img_warped, margin_sa=margin_sa)\n",
    "else:\n",
    "    # Calculate the Sliding window method to find lane lines \n",
    "    left_fit, right_fit, left_fitx, right_fitx, fity, img_binary_out = cal_sliding_window(img_warped,nwindows=nwindows,margin=margin,minpix=minpix)\n",
    "\n",
    "plt.imshow(img_binary_out)"
   ]
  },
  {
   "source": [
    "## 4.3.2. Dynamic calibrate parameters for `cal_sliding_window()`, `cal_search_around()` and `cal_fit_polynomial()`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Calibration Results:\n\n# Color and Gradient Threshold:\n  hls_threshold: (160,255)\n  sobel_threshold: (15,100)\n# Warp perspective:\n  dst_horizontal_offset = 360\n# Sliding Window hyperparams:\n  nwindows = 9\n  margin = 100\n  minpix = 50\n# Search Around hyperparams:\n  margin_sa = 100\n# moving Average max length:\n  moving_avg_max_count = 5\n"
     ]
    }
   ],
   "source": [
    "# Make a list of test images\n",
    "test_images = sorted(glob.glob('test_images/*.jpg'))\n",
    "test_images_index = 0\n",
    "\n",
    "# Create a window with trackbars and callback functions bolow to handle when values are changed\n",
    "cv2.namedWindow(\"Polynomial Fit\")\n",
    "\n",
    "# Threshold trackbars\n",
    "def on_hls_th_l(val):\n",
    "    global hls_threshold\n",
    "    hls_threshold = (val,hls_threshold[1])\n",
    "\n",
    "def on_hls_th_u(val):\n",
    "    global hls_threshold\n",
    "    hls_threshold = (hls_threshold[0],val)\n",
    "\n",
    "def on_sobel_th_l(val):\n",
    "    global sobel_threshold\n",
    "    sobel_threshold = (val,sobel_threshold[1])\n",
    "\n",
    "def on_sobel_th_u(val):\n",
    "    global sobel_threshold\n",
    "    sobel_threshold = (sobel_threshold[0],val)\n",
    "\n",
    "cv2.createTrackbar(\"S Channel Threshold Lower\",\"Polynomial Fit\",hls_threshold[0],255,on_hls_th_l)\n",
    "cv2.createTrackbar(\"S Channel Threshold Upper\",\"Polynomial Fit\",hls_threshold[1],255,on_hls_th_u)\n",
    "cv2.createTrackbar(\"Sobel Threshold Lower\",\"Polynomial Fit\",sobel_threshold[0],255,on_sobel_th_l)\n",
    "cv2.createTrackbar(\"Sobel Threshold Upper\",\"Polynomial Fit\",sobel_threshold[1],255,on_sobel_th_u)\n",
    "\n",
    "# Warp perspective Trackbar\n",
    "def on_warp_dst_x_offset(val):\n",
    "    global dst_vertices\n",
    "    global dst_horizontal_offset\n",
    "    dst_horizontal_offset = val\n",
    "\n",
    "    # Redefine destination vertices to warp\n",
    "    dst_vertices = np.array(\n",
    "        [[src_horizontal_center_x - dst_horizontal_offset, img_undistorted.shape[0]],\n",
    "            [src_horizontal_center_x - dst_horizontal_offset, 0],\n",
    "            [src_horizontal_center_x + dst_horizontal_offset, 0], \n",
    "            [src_horizontal_center_x + dst_horizontal_offset, img_undistorted.shape[0]]],\n",
    "            np.float32)\n",
    "\n",
    "cv2.createTrackbar(\"Dst Horizontal Offset\",\"Polynomial Fit\",dst_horizontal_offset,600,on_warp_dst_x_offset)\n",
    "\n",
    "# Polinomial Fit Trackbars\n",
    "def on_nwindows(val):\n",
    "    global nwindows\n",
    "    nwindows = val\n",
    "\n",
    "def on_margin(val):\n",
    "    global margin\n",
    "    margin = val\n",
    "\n",
    "def on_minpix(val):\n",
    "    global minpix\n",
    "    minpix = val\n",
    "\n",
    "def on_margin_sa(val):\n",
    "    global margin_sa\n",
    "    margin_sa = val\n",
    "\n",
    "def on_moving_avg_max_count(val):\n",
    "    global moving_avg_max_count\n",
    "    global leftt_fit_avg_arr\n",
    "    global right_fit_avg_arr\n",
    "\n",
    "    moving_avg_max_count = val\n",
    "    # Lanes polynomial Fit variables array\n",
    "    if len(left_fit_avg_arr) < moving_avg_max_count:\n",
    "        for i in range(moving_avg_max_count - len(left_fit_avg_arr)):\n",
    "            left_fit_avg_arr.append([])\n",
    "    if len(right_fit_avg_arr) < moving_avg_max_count:\n",
    "        for i in range(moving_avg_max_count - len(right_fit_avg_arr)):\n",
    "            right_fit_avg_arr.append([])\n",
    "\n",
    " \n",
    "cv2.createTrackbar(\"nwindows\",\"Polynomial Fit\",nwindows,50,on_nwindows)\n",
    "cv2.createTrackbar(\"margin\",\"Polynomial Fit\",margin,200,on_margin)\n",
    "cv2.createTrackbar(\"minpix\",\"Polynomial Fit\",minpix,200,on_minpix)\n",
    "cv2.createTrackbar(\"margin_sa\",\"Polynomial Fit\",margin_sa,640,on_margin_sa)\n",
    "cv2.createTrackbar(\"moving_avg_len\",\"Polynomial Fit\",moving_avg_max_count,60,on_moving_avg_max_count)\n",
    "\n",
    "while True:\n",
    "    img_list=[]\n",
    "\n",
    "    # Read image of current index\n",
    "    img = cv2.imread(test_images[test_images_index])\n",
    "\n",
    "    # Undistort image\n",
    "    img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "    img_und_thresholded = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"BGR\")[0]\n",
    "\n",
    "    # Apply perspective transform to the undistorted thresholded image\n",
    "    img_warped = cal_perspective(img_und_thresholded,src_vertices,dst_vertices)\n",
    "\n",
    "    left_fit_avg_arr_filtered, right_fit_avg_arr_filtered = get_fit_avg_arr_filtered()\n",
    "\n",
    "    # If both lane lines fit array arent empty, then search around\n",
    "    if len(left_fit_avg_arr_filtered) > 0 and len(right_fit_avg_arr_filtered) > 0 :\n",
    "        left_fit, right_fit, left_fitx, right_fitx, fity, img_warped_poly_fit = cal_search_around_poly(img_warped, margin_sa=margin_sa)\n",
    "    else:\n",
    "        # Calculate the Sliding window method to find lane lines \n",
    "        left_fit, right_fit, left_fitx, right_fitx, fity, img_warped_poly_fit = cal_sliding_window(img_warped,nwindows=nwindows,margin=margin,minpix=minpix)\n",
    "\n",
    "    img_list.append(img)\n",
    "    img_list.append(img_undistorted)\n",
    "    img_list.append(img_und_thresholded)\n",
    "    img_list.append(img_warped)\n",
    "    img_list.append(img_warped_poly_fit)\n",
    "\n",
    "\n",
    "    title_list = [\"[{}]Original\".format(test_images[test_images_index].split('/')[1]),\"Undistorted\",\"Combined Threshold\",\"Warped\",\"Polynomial Fit\"]\n",
    "\n",
    "    img_compostion = compose_image_arr(img_list,3,title_list=title_list,resize_factor=0.40)\n",
    "\n",
    "    cv2.imshow(\"Polynomial Fit\",img_compostion)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('e'):\n",
    "        test_images_index += 1\n",
    "        if(test_images_index >= len(test_images)):\n",
    "            test_images_index = 0\n",
    "    elif key == ord('w'):\n",
    "        test_images_index -= 1\n",
    "        if(test_images_index < 0):\n",
    "            test_images_index = len(test_images)-1\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"output_images/image_thresholds_cv2.png\",img_compostion)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Calibration Results:\\n\")\n",
    "\n",
    "print(\"# Color and Gradient Threshold:\")\n",
    "print(\"  hls_threshold: ({},{})\".format(hls_threshold[0],hls_threshold[1]))\n",
    "print(\"  sobel_threshold: ({},{})\".format(sobel_threshold[0],sobel_threshold[1]))\n",
    "\n",
    "print(\"# Warp perspective:\")\n",
    "print(\"  dst_horizontal_offset = {}\".format(dst_horizontal_offset))\n",
    "\n",
    "print(\"# Sliding Window hyperparams:\")\n",
    "print(\"  nwindows = {}\".format(nwindows))\n",
    "print(\"  margin = {}\".format(margin))\n",
    "print(\"  minpix = {}\".format(minpix))\n",
    "\n",
    "print(\"# Search Around hyperparams:\")\n",
    "print(\"  margin_sa = {}\".format(margin_sa))\n",
    "\n",
    "print(\"# moving Average max length:\")\n",
    "print(\"  moving_avg_max_count = {}\".format(moving_avg_max_count))"
   ]
  },
  {
   "source": [
    "# 5. Determine the curvature of the lane and vehicle position with respect to center."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_px = 30/720 # meters per pixel in y dimension\n",
    "xm_per_px = 3.7/690 # meters per pixel in x dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_lane_curvature(fity, left_fit_cr, right_fit_cr, factor_x=xm_per_px, factor_y=ym_per_px, cal_meters=False):\n",
    "    \n",
    "    # We'll choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(fity)\n",
    "\n",
    "    if(cal_meters):\n",
    "        # left_fit = np.array([left_fit[0]*factor_x/(factor_y**2), left_fit[1]*factor_x/factor_y, left_fit[2]*factor_x])\n",
    "        # right_fit = np.array([right_fit[0]*factor_x/(factor_y**2), right_fit[1]*factor_x/factor_y, right_fit[2]*factor_x])\n",
    "        left_fitx = left_fit_cr[0]*fity**2 + left_fit_cr[1]*fity + left_fit_cr[2]\n",
    "        right_fitx = right_fit_cr[0]*fity**2 + right_fit_cr[1]*fity + right_fit_cr[2] \n",
    "        left_fit_cr = np.polyfit(fity*factor_y, left_fitx*factor_x, 2)\n",
    "        right_fit_cr = np.polyfit(fity*factor_y, right_fitx*factor_x, 2)\n",
    "\n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_fit_cr[0]*y_eval*factor_y + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*factor_y + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    \n",
    "    return left_curverad, right_curverad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to next image index and reset moving average\n",
    "test_images_index += 1 if test_images_index < (len(test_images)-1) else -(len(test_images)-1)\n",
    "reset_ma()"
   ]
  },
  {
   "source": [
    "## 5.1 Dynamic test of curvature values on different images\n",
    "\n",
    "Instructions:\n",
    " - Press any key different than those described bellow to do a new loop iteration - This is needed because we are using a moving average to fit poly values, so for example, press `r` until fit line stabilizes.\n",
    " - `w` and `e` switch between images in folder `test_images`.\n",
    " - `s` saves image shown to folder `output_images`.\n",
    " - `q` exits simulation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Input Image: straight_lines1.jpg\n",
      "Distance between lane lines: 687.52px\n",
      "Left Radius: 10960.42 \n",
      " Right Radius: 10026.81\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 683.38px\n",
      "Left Radius: 5790.12 \n",
      " Right Radius: 155204.34\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 689.79px\n",
      "Left Radius: 36813.73 \n",
      " Right Radius: 43726.72\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 692.39px\n",
      "Left Radius: 9054.09 \n",
      " Right Radius: 23402.40\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 693.38px\n",
      "Left Radius: 4020.17 \n",
      " Right Radius: 8437.84\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 695.39px\n",
      "Left Radius: 2216.27 \n",
      " Right Radius: 4726.83\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 699.61px\n",
      "Left Radius: 1459.58 \n",
      " Right Radius: 2650.89\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 699.35px\n",
      "Left Radius: 1229.97 \n",
      " Right Radius: 1829.72\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 699.57px\n",
      "Left Radius: 1125.22 \n",
      " Right Radius: 1536.56\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 700.36px\n",
      "Left Radius: 1097.42 \n",
      " Right Radius: 1393.44\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.10px\n",
      "Left Radius: 1097.42 \n",
      " Right Radius: 1325.20\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 1097.42 \n",
      " Right Radius: 1321.01\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 1097.42 \n",
      " Right Radius: 1321.01\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 1097.42 \n",
      " Right Radius: 1321.01\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 1097.42 \n",
      " Right Radius: 1321.01\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 1097.42 \n",
      " Right Radius: 1321.01\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 1097.42 \n",
      " Right Radius: 1321.01\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 1097.42 \n",
      " Right Radius: 1321.01\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 1097.42 \n",
      " Right Radius: 1321.01\n"
     ]
    }
   ],
   "source": [
    "# Make a list of test images\n",
    "test_images = sorted(glob.glob('test_images/*.jpg'))\n",
    "test_images_index = 0\n",
    "reset_ma()\n",
    "\n",
    "while True:\n",
    "    # Read image of current index\n",
    "    img = cv2.imread(test_images[test_images_index])\n",
    "\n",
    "    # Undistort image\n",
    "    img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "    img_und_thresholded = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"BGR\")[0]\n",
    "\n",
    "    # Apply perspective transform to the undistorted thresholded image\n",
    "    img_warped = cal_perspective(img_und_thresholded,src_vertices,dst_vertices)\n",
    "\n",
    "    left_fit_avg_arr_filtered, right_fit_avg_arr_filtered = get_fit_avg_arr_filtered()\n",
    "\n",
    "    # If both lane lines fit array arent empty, then search around\n",
    "    if len(left_fit_avg_arr_filtered) > 0 and len(right_fit_avg_arr_filtered) > 0 :\n",
    "        left_fit, right_fit, left_fitx, right_fitx, fity, img_binary_out = cal_search_around_poly(img_warped, margin_sa=margin_sa)\n",
    "    else:\n",
    "        # Calculate the Sliding window method to find lane lines \n",
    "        left_fit, right_fit, left_fitx, right_fitx, fity, img_binary_out = cal_sliding_window(img_warped,nwindows=nwindows,margin=margin,minpix=minpix)\n",
    "\n",
    "    dist_lines = right_fitx[-1] - left_fitx[-1]\n",
    "    \n",
    "    lane_center_diff_x = (float(right_fitx[-1] + left_fitx[-1])/2 - float(img_warped.shape[1])/2)*xm_per_px\n",
    "\n",
    "    left_curverad, right_curverad = cal_lane_curvature(fity,left_fit,right_fit,factor_x=xm_per_px, factor_y=ym_per_px, cal_meters=True)\n",
    "    \n",
    "\n",
    "    cv2.putText(img_lanes,\"Distance between lane lines: {:0.2f}px\".format(dist_lines),(10,80),cv2.FONT_HERSHEY_SIMPLEX,1.0,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(img_lanes,\"Distance from lane center: {:0.2f}m\".format(lane_center_diff_x),(10,120),cv2.FONT_HERSHEY_SIMPLEX,1.0,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(img_lanes,\"Left Radius: {:0.2f}m \\n Right Radius: {:0.2f}m\".format(left_curverad, right_curverad),(10,160),cv2.FONT_HERSHEY_SIMPLEX,1.0,(0,0,255),2,cv2.LINE_AA)\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Calculate Curvature\", img_binary_out)\n",
    "\n",
    "    key = cv2.waitKey() & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('e'):\n",
    "        test_images_index += 1\n",
    "        if(test_images_index >= len(test_images)):\n",
    "            test_images_index = 0\n",
    "    elif key == ord('w'):\n",
    "        test_images_index -= 1\n",
    "        if(test_images_index < 0):\n",
    "            test_images_index = len(test_images)-1\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"output_images/cal_curvature_{}.png\".format(test_images[test_images_index].split('/')[1].split('.')[0]),img_binary_out)\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "## 6. Warp the detected lane boundaries back onto the original image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane_area(img_undistorted,img_warped, left_fit, right_fit, left_fitx, right_fitx, fity):\n",
    "    if len(img_warped.shape) <= 2:\n",
    "        img_warped_out = np.dstack((img_warped, img_warped, img_warped))\n",
    "    else:\n",
    "        img_warped_out = np.copy(img_warped)\n",
    "\n",
    "    window_img = np.zeros_like(img_warped_out)\n",
    "    lane_window1 = np.array([np.transpose(np.vstack([left_fitx, fity]))])\n",
    "    lane_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx, fity])))])\n",
    "\n",
    "    lane_pts = np.hstack((lane_window1,lane_window2))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(window_img, np.int_([lane_pts]), (0,255, 0))\n",
    "\n",
    "    img_warped_out = cv2.addWeighted(img_warped_out, 1, window_img, 0.3, 0)\n",
    "    # Warp the image using OpenCV warpPerspective()\n",
    "    warped_inv = cv2.warpPerspective(img_warped_out, M_inv, img_undistorted.shape[1::-1])\n",
    "\n",
    "    img_lanes = cv2.addWeighted(img_undistorted, 1, warped_inv, 0.6, 0)\n",
    "\n",
    "    return img_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "lanes center: 656.25\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 687.52px\n",
      "Left Radius: 3537.02 \n",
      " Right Radius: 3236.19\n",
      "lanes center: 656.86\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 683.38px\n",
      "Left Radius: 1869.59 \n",
      " Right Radius: 50249.01\n",
      "lanes center: 666.51\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 689.79px\n",
      "Left Radius: 11884.34 \n",
      " Right Radius: 14105.26\n",
      "lanes center: 671.76\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 692.39px\n",
      "Left Radius: 2926.47 \n",
      " Right Radius: 7531.75\n",
      "lanes center: 675.55\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 693.38px\n",
      "Left Radius: 1301.13 \n",
      " Right Radius: 2715.00\n",
      "lanes center: 682.83\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 695.39px\n",
      "Left Radius: 717.42 \n",
      " Right Radius: 1515.51\n",
      "lanes center: 690.15\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 699.61px\n",
      "Left Radius: 471.70 \n",
      " Right Radius: 851.88\n",
      "lanes center: 691.89\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 699.35px\n",
      "Left Radius: 396.02 \n",
      " Right Radius: 590.97\n",
      "lanes center: 693.29\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 699.57px\n",
      "Left Radius: 361.03 \n",
      " Right Radius: 497.25\n",
      "lanes center: 694.06\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 700.36px\n",
      "Left Radius: 351.70 \n",
      " Right Radius: 451.14\n",
      "lanes center: 694.43\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.10px\n",
      "Left Radius: 351.70 \n",
      " Right Radius: 429.02\n",
      "lanes center: 694.52\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 351.70 \n",
      " Right Radius: 427.66\n",
      "lanes center: 694.52\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 351.70 \n",
      " Right Radius: 427.66\n",
      "lanes center: 694.52\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: test1.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 351.70 \n",
      " Right Radius: 427.66\n",
      "lanes center: 694.52\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 701.29px\n",
      "Left Radius: 351.70 \n",
      " Right Radius: 427.66\n",
      "lanes center: 687.81\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 698.27px\n",
      "Left Radius: 472.26 \n",
      " Right Radius: 465.78\n",
      "lanes center: 681.06\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 695.20px\n",
      "Left Radius: 718.68 \n",
      " Right Radius: 531.71\n",
      "lanes center: 674.23\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 691.95px\n",
      "Left Radius: 1503.08 \n",
      " Right Radius: 650.76\n",
      "lanes center: 667.28\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 688.47px\n",
      "Left Radius: 16425.63 \n",
      " Right Radius: 890.10\n",
      "lanes center: 659.94\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 684.20px\n",
      "Left Radius: 1270.59 \n",
      " Right Radius: 1622.53\n",
      "lanes center: 659.25\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 682.81px\n",
      "Left Radius: 1270.59 \n",
      " Right Radius: 3494.14\n",
      "lanes center: 658.58\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 681.48px\n",
      "Left Radius: 1270.59 \n",
      " Right Radius: 32376.89\n",
      "lanes center: 658.00\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 680.32px\n",
      "Left Radius: 1270.59 \n",
      " Right Radius: 6823.50\n",
      "lanes center: 657.54\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 679.39px\n",
      "Left Radius: 1270.59 \n",
      " Right Radius: 3923.79\n",
      "lanes center: 657.47\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 679.25px\n",
      "Left Radius: 1270.59 \n",
      " Right Radius: 3714.65\n",
      "lanes center: 657.47\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 679.25px\n",
      "Left Radius: 1270.59 \n",
      " Right Radius: 3714.65\n",
      "lanes center: 657.47\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 679.25px\n",
      "Left Radius: 1270.59 \n",
      " Right Radius: 3714.65\n",
      "lanes center: 657.47\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 679.25px\n",
      "Left Radius: 1270.59 \n",
      " Right Radius: 3714.65\n",
      "lanes center: 657.47\n",
      "Img center: 1280\n",
      "\n",
      "Input Image: straight_lines2.jpg\n",
      "Distance between lane lines: 679.25px\n",
      "Left Radius: 1270.59 \n",
      " Right Radius: 3714.65\n",
      "lanes center: 657.47\n",
      "Img center: 1280\n"
     ]
    }
   ],
   "source": [
    "# Make a list of test images\n",
    "test_images = sorted(glob.glob('test_images/*.jpg'))\n",
    "test_images_index = 0\n",
    "reset_ma()\n",
    "\n",
    "while True:\n",
    "    # Read image of current index\n",
    "    img = cv2.imread(test_images[test_images_index])\n",
    "\n",
    "    # Undistort image\n",
    "    img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "    img_und_thresholded = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"BGR\")[0]\n",
    "\n",
    "    # Apply perspective transform to the undistorted thresholded image\n",
    "    img_warped = cal_perspective(img_und_thresholded,src_vertices,dst_vertices)\n",
    "\n",
    "    left_fit_avg_arr_filtered, right_fit_avg_arr_filtered = get_fit_avg_arr_filtered()\n",
    "\n",
    "    # If both lane lines fit array arent empty, then search around\n",
    "    if len(left_fit_avg_arr_filtered) > 0 and len(right_fit_avg_arr_filtered) > 0 :\n",
    "        left_fit, right_fit, left_fitx, right_fitx, fity, img_binary_out = cal_search_around_poly(img_warped, margin_sa=margin_sa)\n",
    "    else:\n",
    "        # Calculate the Sliding window method to find lane lines \n",
    "        left_fit, right_fit, left_fitx, right_fitx, fity, img_binary_out = cal_sliding_window(img_warped,nwindows=nwindows,margin=margin,minpix=minpix)\n",
    "\n",
    "    img_lanes = draw_lane_area(img_undistorted,img_binary_out, left_fit, right_fit, left_fitx, right_fitx, fity)\n",
    "\n",
    "\n",
    "    dist_lines = right_fitx[-1] - left_fitx[-1]\n",
    "    \n",
    "    print(\"lanes center: {:0.2f}\".format(float(right_fitx[-1] + left_fitx[-1])/2))\n",
    "    print(\"Img center: {}\".format(img_warped.shape[1]))\n",
    "\n",
    "    lane_center_diff_x = (float(right_fitx[-1] + left_fitx[-1])/2 - float(img_warped.shape[1])/2)*xm_per_px\n",
    "\n",
    "    left_curverad, right_curverad = cal_lane_curvature(fity,left_fit,right_fit,factor_x=xm_per_px, factor_y=ym_per_px, cal_meters=True)\n",
    "    \n",
    "\n",
    "    cv2.putText(img_lanes,\"Distance between lane lines: {:0.2f}px\".format(dist_lines),(10,80),cv2.FONT_HERSHEY_SIMPLEX,1.0,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(img_lanes,\"Distance from lane center: {:0.2f}m\".format(lane_center_diff_x),(10,120),cv2.FONT_HERSHEY_SIMPLEX,1.0,(0,0,255),2,cv2.LINE_AA)\n",
    "    cv2.putText(img_lanes,\"Left Radius: {:0.2f}m \\n Right Radius: {:0.2f}m\".format(left_curverad, right_curverad),(10,160),cv2.FONT_HERSHEY_SIMPLEX,1.0,(0,0,255),2,cv2.LINE_AA)\n",
    "\n",
    "    img_list=[img_undistorted,img_binary_out,img_lanes]\n",
    "    title_list = [\"[{}]Undistorted\".format(test_images[test_images_index].split('/')[1]),\"Polynomial Fit\",\"Lanes Drawn\"]\n",
    "\n",
    "    img_compostion = compose_image_arr(img_list,3,title_list=title_list,resize_factor=0.50)\n",
    "\n",
    "    cv2.imshow(\"Finding Lane Lines\", img_compostion)\n",
    "\n",
    "    key = cv2.waitKey() & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('e'):\n",
    "        test_images_index += 1\n",
    "        if(test_images_index >= len(test_images)):\n",
    "            test_images_index = 0\n",
    "    elif key == ord('w'):\n",
    "        test_images_index -= 1\n",
    "        if(test_images_index < 0):\n",
    "            test_images_index = len(test_images)-1\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"output_images/draw_lanes_{}.png\".format(test_images[test_images_index].split('/')[1].split('.')[0]),img_lanes)\n",
    "\n",
    "    print(\"\\nInput Image: {}\".format(test_images[test_images_index].split('/')[1]))\n",
    "    print(\"Distance between lane lines: {:0.2f}px\".format(dist_lines))\n",
    "    print(\"Left Radius: {:0.2f} \\n Right Radius: {:0.2f}\".format(left_curverad, right_curverad))\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "source": [
    "## 7. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Dynamic Video Calibration - Full Project"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calibrated Parameters\n",
    "\n",
    "# Color and Gradient Threshold:\n",
    "hls_threshold: (160,255)\n",
    "sobel_threshold: (15,100)\n",
    "# Warp perspective:\n",
    "dst_horizontal_offset = 360\n",
    "# Sliding Window hyperparams:\n",
    "nwindows = 9\n",
    "margin = 100\n",
    "minpix = 50\n",
    "# Search Around hyperparams:\n",
    "margin_sa = 100\n",
    "# moving Average max length:\n",
    "moving_avg_max_count = 10\n",
    "\n",
    "# Reset lanes polynomial fit average arrays\n",
    "left_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "right_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset lanes polynomial fit average arrays\n",
    "def reset_ma():\n",
    "    global left_fit_avg_arr\n",
    "    global right_fit_avg_arr\n",
    "    left_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]\n",
    "    right_fit_avg_arr = [ [] for i in range(moving_avg_max_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['challenge_video.mp4', 'harder_challenge_video.mp4', 'project_video.mp4']\n",
      "/home/renato/.virtualenvs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:41: RankWarning: Polyfit may be poorly conditioned\n",
      "/home/renato/.virtualenvs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:41: RankWarning: Polyfit may be poorly conditioned\n",
      "/home/renato/.virtualenvs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:41: RankWarning: Polyfit may be poorly conditioned\n",
      "/home/renato/.virtualenvs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:41: RankWarning: Polyfit may be poorly conditioned\n",
      "/home/renato/.virtualenvs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:41: RankWarning: Polyfit may be poorly conditioned\n",
      "/home/renato/.virtualenvs/cv/lib/python3.6/site-packages/ipykernel_launcher.py:41: RankWarning: Polyfit may be poorly conditioned\n",
      "Calibration Results:\n",
      "\n",
      "# Color and Gradient Threshold:\n",
      "  hls_threshold: (127,253)\n",
      "  sobel_threshold: (19,105)\n",
      "\n",
      "# Warp perspective:\n",
      "  dst_horizontal_offset = 371\n",
      "\n",
      "# Sliding Window hyperparams:\n",
      "  nwindows = 9\n",
      "  margin = 100\n",
      "  minpix = 50\n",
      "\n",
      "# Search Around hyperparams:\n",
      "  margin_sa = 100\n",
      "\n",
      "# moving Average max length:\n",
      "  moving_avg_max_count = 10\n"
     ]
    }
   ],
   "source": [
    "# Make a list of test videos\n",
    "test_videos = sorted(glob.glob('*.mp4'))\n",
    "test_videos_index = len(test_videos)-1\n",
    "print(test_videos)\n",
    "\n",
    "# Create a window with trackbars and callback functions bolow to handle when values are changed\n",
    "cv2_window_name = \"Advanced Lane Finding\"\n",
    "cv2.namedWindow(cv2_window_name)\n",
    "\n",
    "# Threshold trackbars\n",
    "def on_hls_th_l(val):\n",
    "    global hls_threshold\n",
    "    hls_threshold = (val,hls_threshold[1])\n",
    "\n",
    "def on_hls_th_u(val):\n",
    "    global hls_threshold\n",
    "    hls_threshold = (hls_threshold[0],val)\n",
    "\n",
    "def on_sobel_th_l(val):\n",
    "    global sobel_threshold\n",
    "    sobel_threshold = (val,sobel_threshold[1])\n",
    "\n",
    "def on_sobel_th_u(val):\n",
    "    global sobel_threshold\n",
    "    sobel_threshold = (sobel_threshold[0],val)\n",
    "\n",
    "cv2.createTrackbar(\"S Channel Threshold Lower\",cv2_window_name,hls_threshold[0],255,on_hls_th_l)\n",
    "cv2.createTrackbar(\"S Channel Threshold Upper\",cv2_window_name,hls_threshold[1],255,on_hls_th_u)\n",
    "cv2.createTrackbar(\"Sobel Threshold Lower\",cv2_window_name,sobel_threshold[0],255,on_sobel_th_l)\n",
    "cv2.createTrackbar(\"Sobel Threshold Upper\",cv2_window_name,sobel_threshold[1],255,on_sobel_th_u)\n",
    "\n",
    "# Warp perspective Trackbar\n",
    "def on_warp_dst_x_offset(val):\n",
    "    global dst_vertices\n",
    "    global dst_horizontal_offset\n",
    "    dst_horizontal_offset = val\n",
    "\n",
    "    # Redefine destination vertices to warp\n",
    "    dst_vertices = np.array(\n",
    "        [[src_horizontal_center_x - dst_horizontal_offset, img_undistorted.shape[0]],\n",
    "            [src_horizontal_center_x - dst_horizontal_offset, 0],\n",
    "            [src_horizontal_center_x + dst_horizontal_offset, 0], \n",
    "            [src_horizontal_center_x + dst_horizontal_offset, img_undistorted.shape[0]]],\n",
    "            np.float32)\n",
    "\n",
    "cv2.createTrackbar(\"Dst Horizontal Offset\",cv2_window_name,dst_horizontal_offset,600,on_warp_dst_x_offset)\n",
    "\n",
    "# Polinomial Fit Trackbars\n",
    "def on_nwindows(val):\n",
    "    global nwindows\n",
    "    nwindows = val\n",
    "\n",
    "def on_margin(val):\n",
    "    global margin\n",
    "    margin = val\n",
    "\n",
    "def on_minpix(val):\n",
    "    global minpix\n",
    "    minpix = val\n",
    "\n",
    "def on_margin_sa(val):\n",
    "    global margin_sa\n",
    "    margin_sa = val\n",
    "\n",
    "def on_moving_avg_max_count(val):\n",
    "    global moving_avg_max_count\n",
    "    global leftt_fit_avg_arr\n",
    "    global right_fit_avg_arr\n",
    "\n",
    "    moving_avg_max_count = val\n",
    "    # Lanes polynomial Fit variables array\n",
    "    if len(left_fit_avg_arr) < moving_avg_max_count:\n",
    "        for i in range(moving_avg_max_count - len(left_fit_avg_arr)):\n",
    "            left_fit_avg_arr.append([])\n",
    "    if len(right_fit_avg_arr) < moving_avg_max_count:\n",
    "        for i in range(moving_avg_max_count - len(right_fit_avg_arr)):\n",
    "            right_fit_avg_arr.append([])\n",
    "\n",
    " \n",
    "cv2.createTrackbar(\"nwindows\",cv2_window_name,nwindows,50,on_nwindows)\n",
    "cv2.createTrackbar(\"margin\",cv2_window_name,margin,200,on_margin)\n",
    "cv2.createTrackbar(\"minpix\",cv2_window_name,minpix,200,on_minpix)\n",
    "cv2.createTrackbar(\"margin_sa\",cv2_window_name,margin_sa,640,on_margin_sa)\n",
    "cv2.createTrackbar(\"moving_avg_len\",cv2_window_name,moving_avg_max_count,60,on_moving_avg_max_count)\n",
    "\n",
    "while True:\n",
    "    img_list=[]\n",
    "\n",
    "    # Read a frame from video of current index\n",
    "    ret,img = cap.read()\n",
    "\n",
    "    if ret == False:\n",
    "        cap = cv2.VideoCapture(test_videos[test_videos_index])\n",
    "        continue\n",
    "\n",
    "    # Undistort image\n",
    "    img_undistorted = cal_undistort(img, mtx, dist)\n",
    "\n",
    "    img_und_thresholded = cal_threshold(img_undistorted,hls_threshold=hls_threshold,sobel_threshold=sobel_threshold,color_space=\"BGR\")[0]\n",
    "\n",
    "    # Apply perspective transform to the undistorted thresholded image\n",
    "    img_warped = cal_perspective(img_und_thresholded,src_vertices,dst_vertices)\n",
    "\n",
    "    left_fit_avg_arr_filtered, right_fit_avg_arr_filtered = get_fit_avg_arr_filtered()\n",
    "\n",
    "    # If both lane lines fit array arent empty, then search around\n",
    "    if len(left_fit_avg_arr_filtered) > 0 and len(right_fit_avg_arr_filtered) > 0 :\n",
    "        left_fit, right_fit, left_fitx, right_fitx, fity, img_warped_poly_fit = cal_search_around_poly(img_warped, margin_sa=margin_sa)\n",
    "    else:\n",
    "        # Calculate the Sliding window method to find lane lines \n",
    "        left_fit, right_fit, left_fitx, right_fitx, fity, img_warped_poly_fit = cal_sliding_window(img_warped,nwindows=nwindows,margin=margin,minpix=minpix)\n",
    "\n",
    "    img_list.append(img)\n",
    "    img_list.append(img_undistorted)\n",
    "    img_list.append(img_und_thresholded)\n",
    "    img_list.append(img_warped)\n",
    "    img_list.append(img_warped_poly_fit)\n",
    "\n",
    "\n",
    "    title_list = [\"[{}]Original\".format(test_videos[test_videos_index].split('.')[0]),\"Undistorted\",\"Combined Threshold\",\"Warped\",\"Polynomial Fit\"]\n",
    "\n",
    "    img_compostion = compose_image_arr(img_list,3,title_list=title_list,resize_factor=0.40)\n",
    "\n",
    "    cv2.imshow(cv2_window_name,img_compostion)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    elif key == ord('r'):\n",
    "        reset_ma()\n",
    "    elif key == ord('e'):\n",
    "        test_videos_index += 1\n",
    "        if(test_videos_index >= len(test_videos)):\n",
    "            test_videos_index = 0\n",
    "        cap = cv2.VideoCapture(test_videos[test_videos_index])\n",
    "        reset_ma()\n",
    "    elif key == ord('w'):\n",
    "        test_videos_index -= 1\n",
    "        if(test_videos_index < 0):\n",
    "            test_videos_index = len(test_videos)-1\n",
    "        cap = cv2.VideoCapture(test_videos[test_videos_index])\n",
    "        reset_ma()\n",
    "    elif key == ord('s'):\n",
    "        cv2.imwrite(\"output_images/video_composition_{}.png\".format(test_videos[test_videos_index].split('.')[0]),img_compostion)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Calibration Results:\")\n",
    "\n",
    "print(\"\\n# Color and Gradient Threshold:\")\n",
    "print(\"  hls_threshold: ({},{})\".format(hls_threshold[0],hls_threshold[1]))\n",
    "print(\"  sobel_threshold: ({},{})\".format(sobel_threshold[0],sobel_threshold[1]))\n",
    "\n",
    "print(\"\\n# Warp perspective:\")\n",
    "print(\"  dst_horizontal_offset = {}\".format(dst_horizontal_offset))\n",
    "\n",
    "print(\"\\n# Sliding Window hyperparams:\")\n",
    "print(\"  nwindows = {}\".format(nwindows))\n",
    "print(\"  margin = {}\".format(margin))\n",
    "print(\"  minpix = {}\".format(minpix))\n",
    "\n",
    "print(\"\\n# Search Around hyperparams:\")\n",
    "print(\"  margin_sa = {}\".format(margin_sa))\n",
    "\n",
    "print(\"\\n# moving Average max length:\")\n",
    "print(\"  moving_avg_max_count = {}\".format(moving_avg_max_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.9 64-bit ('cv': virtualenvwrapper)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "interpreter": {
   "hash": "6a0b733e851c76961a3549792236d53668940e76a299dd69e80c674f6368f9f8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}